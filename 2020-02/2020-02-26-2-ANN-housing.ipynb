{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(models.Model):\n",
    "    def __init__(self, Nin, Nh, Nout):\n",
    "        hidden = layers.Dense(Nh)\n",
    "        output = layers.Dense(Nout)\n",
    "        relu = layers.Activation('relu')\n",
    "        \n",
    "        x = layers.Input(shape=(Nin,))\n",
    "        h = relu(hidden(x))\n",
    "        y = output(h)\n",
    "\n",
    "        super().__init__(x, y)\n",
    "        \n",
    "        self.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, Y_train), (X_test, Y_test) = datasets.boston_housing.load_data()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as ply\n",
    "from keraspp.skeras import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/500\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 495.6410 - val_loss: 132.6873\n",
      "Epoch 2/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 116.8621 - val_loss: 160.9026\n",
      "Epoch 3/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 97.0168 - val_loss: 81.4735\n",
      "Epoch 4/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 70.6381 - val_loss: 84.9676\n",
      "Epoch 5/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 62.7408 - val_loss: 63.9463\n",
      "Epoch 6/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 60.0044 - val_loss: 97.9427\n",
      "Epoch 7/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 57.7582 - val_loss: 67.6893\n",
      "Epoch 8/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 55.9638 - val_loss: 53.7061\n",
      "Epoch 9/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 46.5589 - val_loss: 58.1614\n",
      "Epoch 10/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 52.4165 - val_loss: 60.0307\n",
      "Epoch 11/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 46.4355 - val_loss: 54.4271\n",
      "Epoch 12/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 48.7670 - val_loss: 50.2492\n",
      "Epoch 13/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 41.9518 - val_loss: 51.4353\n",
      "Epoch 14/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 43.1054 - val_loss: 42.2318\n",
      "Epoch 15/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 42.2992 - val_loss: 39.8935\n",
      "Epoch 16/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 37.6392 - val_loss: 38.5673\n",
      "Epoch 17/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 34.2888 - val_loss: 35.8240\n",
      "Epoch 18/500\n",
      "323/323 [==============================] - 0s 77us/step - loss: 33.1956 - val_loss: 56.1278\n",
      "Epoch 19/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 49.4702 - val_loss: 71.5643\n",
      "Epoch 20/500\n",
      "323/323 [==============================] - 0s 59us/step - loss: 56.3265 - val_loss: 87.5679\n",
      "Epoch 21/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 54.0913 - val_loss: 77.6919\n",
      "Epoch 22/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 66.9251 - val_loss: 102.4112\n",
      "Epoch 23/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 82.8324 - val_loss: 44.9277\n",
      "Epoch 24/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 32.2835 - val_loss: 33.2763\n",
      "Epoch 25/500\n",
      "323/323 [==============================] - 0s 76us/step - loss: 29.9581 - val_loss: 32.5088\n",
      "Epoch 26/500\n",
      "323/323 [==============================] - 0s 78us/step - loss: 31.5049 - val_loss: 36.5378\n",
      "Epoch 27/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 31.0410 - val_loss: 29.2219\n",
      "Epoch 28/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 28.2511 - val_loss: 29.9298\n",
      "Epoch 29/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 28.1078 - val_loss: 36.0150\n",
      "Epoch 30/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 28.5967 - val_loss: 27.8126\n",
      "Epoch 31/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 27.3058 - val_loss: 28.3570\n",
      "Epoch 32/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 26.7221 - val_loss: 37.9034\n",
      "Epoch 33/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 41.3142 - val_loss: 72.5955\n",
      "Epoch 34/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 49.7107 - val_loss: 67.7120\n",
      "Epoch 35/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 52.2182 - val_loss: 48.5387\n",
      "Epoch 36/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 38.7943 - val_loss: 67.9038\n",
      "Epoch 37/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 42.6617 - val_loss: 72.1952\n",
      "Epoch 38/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 55.8779 - val_loss: 87.5508\n",
      "Epoch 39/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 51.4070 - val_loss: 27.4537\n",
      "Epoch 40/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 25.4400 - val_loss: 27.9660\n",
      "Epoch 41/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 26.9241 - val_loss: 27.9070\n",
      "Epoch 42/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 33.0687 - val_loss: 32.6952\n",
      "Epoch 43/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 44.8370 - val_loss: 28.4398\n",
      "Epoch 44/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 36.6387 - val_loss: 26.5113\n",
      "Epoch 45/500\n",
      "323/323 [==============================] - 0s 69us/step - loss: 24.8213 - val_loss: 30.3795\n",
      "Epoch 46/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 28.5293 - val_loss: 26.0385\n",
      "Epoch 47/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 28.7640 - val_loss: 47.4900\n",
      "Epoch 48/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 41.4959 - val_loss: 63.2368\n",
      "Epoch 49/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 40.9166 - val_loss: 48.1712\n",
      "Epoch 50/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 34.0172 - val_loss: 25.0627\n",
      "Epoch 51/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 24.4035 - val_loss: 24.6626\n",
      "Epoch 52/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 24.6321 - val_loss: 28.0047\n",
      "Epoch 53/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 27.6607 - val_loss: 24.0578\n",
      "Epoch 54/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 24.1417 - val_loss: 27.4819\n",
      "Epoch 55/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 23.9172 - val_loss: 28.8650\n",
      "Epoch 56/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 24.4354 - val_loss: 27.6813\n",
      "Epoch 57/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 25.0159 - val_loss: 24.8316\n",
      "Epoch 58/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 23.6549 - val_loss: 36.2469\n",
      "Epoch 59/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 37.5063 - val_loss: 23.7194\n",
      "Epoch 60/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 24.6104 - val_loss: 26.3632\n",
      "Epoch 61/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 23.6041 - val_loss: 24.9252\n",
      "Epoch 62/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 25.1095 - val_loss: 25.2409\n",
      "Epoch 63/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 23.5288 - val_loss: 26.2422\n",
      "Epoch 64/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 27.9222 - val_loss: 46.0220\n",
      "Epoch 65/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 43.9903 - val_loss: 23.9402\n",
      "Epoch 66/500\n",
      "323/323 [==============================] - 0s 84us/step - loss: 26.7519 - val_loss: 22.7322\n",
      "Epoch 67/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 27.2381 - val_loss: 22.8049\n",
      "Epoch 68/500\n",
      "323/323 [==============================] - 0s 59us/step - loss: 24.0172 - val_loss: 31.1111\n",
      "Epoch 69/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 26.7752 - val_loss: 30.3186\n",
      "Epoch 70/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 24.6487 - val_loss: 33.3143\n",
      "Epoch 71/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 35.5745 - val_loss: 28.1404\n",
      "Epoch 72/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 25.7859 - val_loss: 36.8526\n",
      "Epoch 73/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 47.8158 - val_loss: 23.1112\n",
      "Epoch 74/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 24.0822 - val_loss: 27.0854\n",
      "Epoch 75/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 24.3264 - val_loss: 22.6054\n",
      "Epoch 76/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 23.7645 - val_loss: 22.4455\n",
      "Epoch 77/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 23.0646 - val_loss: 23.8804\n",
      "Epoch 78/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 24.7645 - val_loss: 27.8174\n",
      "Epoch 79/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 33.3722 - val_loss: 37.5415\n",
      "Epoch 80/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 36.6185 - val_loss: 22.2517\n",
      "Epoch 81/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 23.0048 - val_loss: 22.1387\n",
      "Epoch 82/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 23.2114 - val_loss: 25.9510\n",
      "Epoch 83/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 28.8911 - val_loss: 37.6902\n",
      "Epoch 84/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 27.1187 - val_loss: 29.5050\n",
      "Epoch 85/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 30.4509 - val_loss: 27.7056\n",
      "Epoch 86/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 30.8086 - val_loss: 25.0407\n",
      "Epoch 87/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 24.0503 - val_loss: 22.1379\n",
      "Epoch 88/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 23.0015 - val_loss: 26.2888\n",
      "Epoch 89/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 25.2552 - val_loss: 42.7931\n",
      "Epoch 90/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 37.4057 - val_loss: 23.4056\n",
      "Epoch 91/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 23.6718 - val_loss: 24.3660\n",
      "Epoch 92/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 24.3026 - val_loss: 21.6483\n",
      "Epoch 93/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 25.7170 - val_loss: 28.9204\n",
      "Epoch 94/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 24.3366 - val_loss: 21.5853\n",
      "Epoch 95/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 22.9236 - val_loss: 28.6858\n",
      "Epoch 96/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 24.3015 - val_loss: 21.6583\n",
      "Epoch 97/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 22.7920 - val_loss: 22.3477\n",
      "Epoch 98/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 23.3966 - val_loss: 22.0510\n",
      "Epoch 99/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 28.4674 - val_loss: 35.2716\n",
      "Epoch 100/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 35.5115 - val_loss: 36.2750\n",
      "Epoch 101/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 28.8779 - val_loss: 21.5932\n",
      "Epoch 102/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 23.8440 - val_loss: 35.9863\n",
      "Epoch 103/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 36.0042 - val_loss: 25.9286\n",
      "Epoch 104/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 27.9993 - val_loss: 22.2454\n",
      "Epoch 105/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 22.4495 - val_loss: 21.9084\n",
      "Epoch 106/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 22.7174 - val_loss: 22.9337\n",
      "Epoch 107/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 22.7345 - val_loss: 30.1582\n",
      "Epoch 108/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 24.7618 - val_loss: 22.0359\n",
      "Epoch 109/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 23.2395 - val_loss: 22.1888\n",
      "Epoch 110/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 22.4831 - val_loss: 21.1619\n",
      "Epoch 111/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 23.3041 - val_loss: 26.1920\n",
      "Epoch 112/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 23.4711 - val_loss: 25.0483\n",
      "Epoch 113/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 24.2311 - val_loss: 21.0457\n",
      "Epoch 114/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 23.2048 - val_loss: 31.2574\n",
      "Epoch 115/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 31.5750 - val_loss: 39.0642\n",
      "Epoch 116/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 29.5163 - val_loss: 21.1067\n",
      "Epoch 117/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 22.6979 - val_loss: 21.9535\n",
      "Epoch 118/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 23.6092 - val_loss: 21.1999\n",
      "Epoch 119/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 24.6838 - val_loss: 22.4817\n",
      "Epoch 120/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 22.6141 - val_loss: 21.1595\n",
      "Epoch 121/500\n",
      "323/323 [==============================] - 0s 88us/step - loss: 23.3762 - val_loss: 30.6717\n",
      "Epoch 122/500\n",
      "323/323 [==============================] - 0s 69us/step - loss: 31.1776 - val_loss: 23.0295\n",
      "Epoch 123/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 22.5446 - val_loss: 29.2462\n",
      "Epoch 124/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 28.8666 - val_loss: 23.6315\n",
      "Epoch 125/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 29.0684 - val_loss: 23.7241\n",
      "Epoch 126/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 25.8434 - val_loss: 29.9158\n",
      "Epoch 127/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 27.3296 - val_loss: 24.8151\n",
      "Epoch 128/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 23.0506 - val_loss: 21.2531\n",
      "Epoch 129/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 22.4305 - val_loss: 21.9351\n",
      "Epoch 130/500\n",
      "323/323 [==============================] - 0s 61us/step - loss: 22.2389 - val_loss: 30.6256\n",
      "Epoch 131/500\n",
      "323/323 [==============================] - 0s 72us/step - loss: 26.3380 - val_loss: 22.4470\n",
      "Epoch 132/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 23.0591 - val_loss: 22.5573\n",
      "Epoch 133/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 22.3895 - val_loss: 22.7381\n",
      "Epoch 134/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 23.3205 - val_loss: 32.8778\n",
      "Epoch 135/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 30.7528 - val_loss: 25.3923\n",
      "Epoch 136/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 29.8026 - val_loss: 51.0300\n",
      "Epoch 137/500\n",
      "323/323 [==============================] - 0s 56us/step - loss: 40.6997 - val_loss: 29.4326\n",
      "Epoch 138/500\n",
      "323/323 [==============================] - 0s 63us/step - loss: 33.6888 - val_loss: 22.9210\n",
      "Epoch 139/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 30.4079 - val_loss: 22.8253\n",
      "Epoch 140/500\n",
      "323/323 [==============================] - 0s 58us/step - loss: 23.5053 - val_loss: 21.5351\n",
      "Epoch 141/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 22.2232 - val_loss: 34.2891\n",
      "Epoch 142/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 28.9923 - val_loss: 21.8379\n",
      "Epoch 143/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 29.1800 - val_loss: 21.1479\n",
      "Epoch 144/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 21.9052 - val_loss: 27.2116\n",
      "Epoch 145/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 24.3448 - val_loss: 28.5751\n",
      "Epoch 146/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 26.2326 - val_loss: 21.3310\n",
      "Epoch 147/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 23.1321 - val_loss: 24.4141\n",
      "Epoch 148/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 23.0944 - val_loss: 20.8112\n",
      "Epoch 149/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 22.1285 - val_loss: 28.7204\n",
      "Epoch 150/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 28.6583 - val_loss: 41.7276\n",
      "Epoch 151/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 29.0468 - val_loss: 34.5632\n",
      "Epoch 152/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 29.4169 - val_loss: 22.5753\n",
      "Epoch 153/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 22.8358 - val_loss: 25.6197\n",
      "Epoch 154/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 24.8892 - val_loss: 20.5556\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 43us/step - loss: 22.1933 - val_loss: 24.7759\n",
      "Epoch 156/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 23.9445 - val_loss: 23.0148\n",
      "Epoch 157/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 24.2523 - val_loss: 28.5892\n",
      "Epoch 158/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 26.9300 - val_loss: 20.7103\n",
      "Epoch 159/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 21.9520 - val_loss: 20.6550\n",
      "Epoch 160/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 21.9506 - val_loss: 22.2416\n",
      "Epoch 161/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 26.6662 - val_loss: 20.6665\n",
      "Epoch 162/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 22.6214 - val_loss: 20.8321\n",
      "Epoch 163/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 22.3473 - val_loss: 35.8810\n",
      "Epoch 164/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 37.0162 - val_loss: 21.0917\n",
      "Epoch 165/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 22.7801 - val_loss: 23.3369\n",
      "Epoch 166/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 23.2924 - val_loss: 23.9231\n",
      "Epoch 167/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 22.8181 - val_loss: 20.6149\n",
      "Epoch 168/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 22.5303 - val_loss: 23.6642\n",
      "Epoch 169/500\n",
      "323/323 [==============================] - 0s 58us/step - loss: 22.0789 - val_loss: 22.4753\n",
      "Epoch 170/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 22.4774 - val_loss: 20.2642\n",
      "Epoch 171/500\n",
      "323/323 [==============================] - 0s 64us/step - loss: 22.1806 - val_loss: 20.0981\n",
      "Epoch 172/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 21.9820 - val_loss: 20.3010\n",
      "Epoch 173/500\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.8070 - val_loss: 21.3758\n",
      "Epoch 174/500\n",
      "323/323 [==============================] - 0s 59us/step - loss: 22.2560 - val_loss: 20.1135\n",
      "Epoch 175/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 22.4198 - val_loss: 20.6984\n",
      "Epoch 176/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 21.9243 - val_loss: 20.4929\n",
      "Epoch 177/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 21.9678 - val_loss: 20.0473\n",
      "Epoch 178/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 21.6717 - val_loss: 22.1078\n",
      "Epoch 179/500\n",
      "323/323 [==============================] - 0s 58us/step - loss: 23.0795 - val_loss: 20.3856\n",
      "Epoch 180/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 22.2639 - val_loss: 29.9097\n",
      "Epoch 181/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 31.2824 - val_loss: 20.4358\n",
      "Epoch 182/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 22.0905 - val_loss: 22.2325\n",
      "Epoch 183/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 21.9645 - val_loss: 22.0847\n",
      "Epoch 184/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 21.9708 - val_loss: 24.7930\n",
      "Epoch 185/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 27.9650 - val_loss: 21.2871\n",
      "Epoch 186/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 23.8924 - val_loss: 20.9852\n",
      "Epoch 187/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 29.9158 - val_loss: 37.6129\n",
      "Epoch 188/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 26.0633 - val_loss: 23.7223\n",
      "Epoch 189/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 23.4891 - val_loss: 20.6303\n",
      "Epoch 190/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 23.5864 - val_loss: 23.7164\n",
      "Epoch 191/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 26.1903 - val_loss: 20.1623\n",
      "Epoch 192/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 22.2425 - val_loss: 20.4126\n",
      "Epoch 193/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 23.6224 - val_loss: 22.0558\n",
      "Epoch 194/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 24.9022 - val_loss: 25.5901\n",
      "Epoch 195/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 25.2172 - val_loss: 20.2855\n",
      "Epoch 196/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 21.8457 - val_loss: 22.6332\n",
      "Epoch 197/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 22.6016 - val_loss: 20.3625\n",
      "Epoch 198/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 21.7397 - val_loss: 20.1543\n",
      "Epoch 199/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 23.0162 - val_loss: 20.8066\n",
      "Epoch 200/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 22.0575 - val_loss: 20.3520\n",
      "Epoch 201/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 22.2777 - val_loss: 20.4951\n",
      "Epoch 202/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 21.7895 - val_loss: 24.9159\n",
      "Epoch 203/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 23.0440 - val_loss: 20.7819\n",
      "Epoch 204/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 21.8794 - val_loss: 22.3059\n",
      "Epoch 205/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 24.4748 - val_loss: 22.4478\n",
      "Epoch 206/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 23.5944 - val_loss: 20.3883\n",
      "Epoch 207/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 21.8427 - val_loss: 21.5378\n",
      "Epoch 208/500\n",
      "323/323 [==============================] - 0s 73us/step - loss: 22.7891 - val_loss: 31.2157\n",
      "Epoch 209/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 25.2069 - val_loss: 20.1894\n",
      "Epoch 210/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 21.9441 - val_loss: 20.2225\n",
      "Epoch 211/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 21.5945 - val_loss: 20.5458\n",
      "Epoch 212/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 22.5887 - val_loss: 20.6007\n",
      "Epoch 213/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 21.8689 - val_loss: 29.1763\n",
      "Epoch 214/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 25.7455 - val_loss: 20.1501\n",
      "Epoch 215/500\n",
      "323/323 [==============================] - 0s 27us/step - loss: 21.7390 - val_loss: 20.5348\n",
      "Epoch 216/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 23.2325 - val_loss: 22.0272\n",
      "Epoch 217/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 23.8022 - val_loss: 27.3074\n",
      "Epoch 218/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 23.7156 - val_loss: 20.3406\n",
      "Epoch 219/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 21.9567 - val_loss: 28.6452\n",
      "Epoch 220/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 28.5202 - val_loss: 30.9109\n",
      "Epoch 221/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 22.9520 - val_loss: 20.1010\n",
      "Epoch 222/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 21.5385 - val_loss: 20.1773\n",
      "Epoch 223/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 21.6610 - val_loss: 23.1124\n",
      "Epoch 224/500\n",
      "323/323 [==============================] - 0s 55us/step - loss: 21.7126 - val_loss: 20.0671\n",
      "Epoch 225/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 21.6362 - val_loss: 20.1700\n",
      "Epoch 226/500\n",
      "323/323 [==============================] - 0s 77us/step - loss: 21.6007 - val_loss: 20.8003\n",
      "Epoch 227/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 21.3677 - val_loss: 20.2925\n",
      "Epoch 228/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 22.0934 - val_loss: 21.4274\n",
      "Epoch 229/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 24.0561 - val_loss: 20.4125\n",
      "Epoch 230/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 23.1195 - val_loss: 24.2837\n",
      "Epoch 231/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 22.3053 - val_loss: 20.8022\n",
      "Epoch 232/500\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.9117 - val_loss: 21.9805\n",
      "Epoch 233/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 21.5933 - val_loss: 20.0752\n",
      "Epoch 234/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 22.7403 - val_loss: 33.1319\n",
      "Epoch 235/500\n",
      "323/323 [==============================] - 0s 27us/step - loss: 25.9363 - val_loss: 20.6987\n",
      "Epoch 236/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 21.5474 - val_loss: 20.3140\n",
      "Epoch 237/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 21.6955 - val_loss: 20.4574\n",
      "Epoch 238/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 21.4672 - val_loss: 19.9964\n",
      "Epoch 239/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 23.0154 - val_loss: 20.8905\n",
      "Epoch 240/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 22.8276 - val_loss: 23.3666\n",
      "Epoch 241/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 23.5027 - val_loss: 20.4196\n",
      "Epoch 242/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 21.7946 - val_loss: 19.9077\n",
      "Epoch 243/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 21.7485 - val_loss: 21.5928\n",
      "Epoch 244/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 22.9705 - val_loss: 20.5844\n",
      "Epoch 245/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 22.2280 - val_loss: 20.3191\n",
      "Epoch 246/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 22.9231 - val_loss: 29.8101\n",
      "Epoch 247/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 28.9897 - val_loss: 23.9696\n",
      "Epoch 248/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 22.6089 - val_loss: 20.0673\n",
      "Epoch 249/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 21.3737 - val_loss: 20.2188\n",
      "Epoch 250/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 22.5585 - val_loss: 22.2109\n",
      "Epoch 251/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 21.7002 - val_loss: 20.3824\n",
      "Epoch 252/500\n",
      "323/323 [==============================] - 0s 66us/step - loss: 21.7314 - val_loss: 20.5563\n",
      "Epoch 253/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 23.4295 - val_loss: 28.0357\n",
      "Epoch 254/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 27.1428 - val_loss: 19.8134\n",
      "Epoch 255/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 21.5334 - val_loss: 21.9860\n",
      "Epoch 256/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 22.1046 - val_loss: 20.1171\n",
      "Epoch 257/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 21.5907 - val_loss: 20.0796\n",
      "Epoch 258/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 21.2708 - val_loss: 22.2593\n",
      "Epoch 259/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 27.2432 - val_loss: 25.4232\n",
      "Epoch 260/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 26.0281 - val_loss: 21.5664\n",
      "Epoch 261/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 21.4280 - val_loss: 19.9455\n",
      "Epoch 262/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 21.4381 - val_loss: 20.3155\n",
      "Epoch 263/500\n",
      "323/323 [==============================] - 0s 66us/step - loss: 21.9420 - val_loss: 20.1661\n",
      "Epoch 264/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 21.1224 - val_loss: 21.8379\n",
      "Epoch 265/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 22.8667 - val_loss: 21.5252\n",
      "Epoch 266/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 24.6762 - val_loss: 23.7508\n",
      "Epoch 267/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 24.8818 - val_loss: 21.5126\n",
      "Epoch 268/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 23.5831 - val_loss: 20.0361\n",
      "Epoch 269/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 21.5727 - val_loss: 23.1623\n",
      "Epoch 270/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 26.3263 - val_loss: 20.9276\n",
      "Epoch 271/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 21.9735 - val_loss: 21.0645\n",
      "Epoch 272/500\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.8762 - val_loss: 27.7760\n",
      "Epoch 273/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 29.7899 - val_loss: 25.3232\n",
      "Epoch 274/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 21.8735 - val_loss: 20.9847\n",
      "Epoch 275/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 21.2899 - val_loss: 19.6385\n",
      "Epoch 276/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 21.6473 - val_loss: 19.5106\n",
      "Epoch 277/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 20.9218 - val_loss: 20.9312\n",
      "Epoch 278/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 21.2654 - val_loss: 19.5492\n",
      "Epoch 279/500\n",
      "323/323 [==============================] - 0s 58us/step - loss: 21.0451 - val_loss: 19.5573\n",
      "Epoch 280/500\n",
      "323/323 [==============================] - ETA: 0s - loss: 16.32 - 0s 57us/step - loss: 21.3583 - val_loss: 28.7485\n",
      "Epoch 281/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 24.0169 - val_loss: 19.7108\n",
      "Epoch 282/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 21.5179 - val_loss: 37.2939\n",
      "Epoch 283/500\n",
      "323/323 [==============================] - 0s 46us/step - loss: 35.4911 - val_loss: 19.4754\n",
      "Epoch 284/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 20.6073 - val_loss: 19.5452\n",
      "Epoch 285/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 20.9154 - val_loss: 19.8990\n",
      "Epoch 286/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 25.3947 - val_loss: 19.7609\n",
      "Epoch 287/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 21.4947 - val_loss: 19.0723\n",
      "Epoch 288/500\n",
      "323/323 [==============================] - 0s 24us/step - loss: 22.8740 - val_loss: 20.9210\n",
      "Epoch 289/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 22.1408 - val_loss: 19.6171\n",
      "Epoch 290/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 20.3751 - val_loss: 18.9731\n",
      "Epoch 291/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 20.6679 - val_loss: 27.3687\n",
      "Epoch 292/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 21.7062 - val_loss: 20.2245\n",
      "Epoch 293/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 24.5631 - val_loss: 45.9691\n",
      "Epoch 294/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 35.4939 - val_loss: 19.3590\n",
      "Epoch 295/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 20.4461 - val_loss: 19.2623\n",
      "Epoch 296/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 20.6715 - val_loss: 25.7803\n",
      "Epoch 297/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 22.6100 - val_loss: 19.1335\n",
      "Epoch 298/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 21.0836 - val_loss: 22.2214\n",
      "Epoch 299/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 21.7052 - val_loss: 24.0439\n",
      "Epoch 300/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 22.7731 - val_loss: 19.0390\n",
      "Epoch 301/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 20.3237 - val_loss: 19.5133\n",
      "Epoch 302/500\n",
      "323/323 [==============================] - 0s 25us/step - loss: 20.3128 - val_loss: 19.2456\n",
      "Epoch 303/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 20.5584 - val_loss: 18.2889\n",
      "Epoch 304/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 20.1966 - val_loss: 19.3087\n",
      "Epoch 305/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 20.2598 - val_loss: 18.3846\n",
      "Epoch 306/500\n",
      "323/323 [==============================] - 0s 25us/step - loss: 22.3592 - val_loss: 19.1859\n",
      "Epoch 307/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 20.2820 - val_loss: 18.5498\n",
      "Epoch 308/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 20.1500 - val_loss: 18.2224\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 34us/step - loss: 19.9958 - val_loss: 21.7491\n",
      "Epoch 310/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 20.5115 - val_loss: 19.8241\n",
      "Epoch 311/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 19.9933 - val_loss: 18.5897\n",
      "Epoch 312/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 20.6336 - val_loss: 18.3171\n",
      "Epoch 313/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 19.3918 - val_loss: 21.0878\n",
      "Epoch 314/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 20.3459 - val_loss: 17.7637\n",
      "Epoch 315/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 20.2872 - val_loss: 19.9944\n",
      "Epoch 316/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 20.4333 - val_loss: 17.9669\n",
      "Epoch 317/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 19.7040 - val_loss: 17.9956\n",
      "Epoch 318/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 22.4060 - val_loss: 17.4501\n",
      "Epoch 319/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 21.4849 - val_loss: 18.3624\n",
      "Epoch 320/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 20.5997 - val_loss: 22.1531\n",
      "Epoch 321/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 21.1919 - val_loss: 18.8057\n",
      "Epoch 322/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 20.4011 - val_loss: 19.4793\n",
      "Epoch 323/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 22.5662 - val_loss: 18.9127\n",
      "Epoch 324/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 22.3015 - val_loss: 19.3147\n",
      "Epoch 325/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 20.2155 - val_loss: 18.3670\n",
      "Epoch 326/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 19.4441 - val_loss: 21.8588\n",
      "Epoch 327/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 21.1475 - val_loss: 18.0597\n",
      "Epoch 328/500\n",
      "323/323 [==============================] - 0s 60us/step - loss: 19.5716 - val_loss: 18.1359\n",
      "Epoch 329/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 20.7779 - val_loss: 23.6629\n",
      "Epoch 330/500\n",
      "323/323 [==============================] - 0s 48us/step - loss: 20.2350 - val_loss: 22.7746\n",
      "Epoch 331/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 21.4399 - val_loss: 18.5499\n",
      "Epoch 332/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 19.1792 - val_loss: 17.2973\n",
      "Epoch 333/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 19.6816 - val_loss: 17.8920\n",
      "Epoch 334/500\n",
      "323/323 [==============================] - 0s 27us/step - loss: 22.7550 - val_loss: 27.8852\n",
      "Epoch 335/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 26.5360 - val_loss: 17.6509\n",
      "Epoch 336/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 19.1285 - val_loss: 17.8522\n",
      "Epoch 337/500\n",
      "323/323 [==============================] - 0s 445us/step - loss: 19.3592 - val_loss: 22.8848\n",
      "Epoch 338/500\n",
      "323/323 [==============================] - 0s 27us/step - loss: 21.0497 - val_loss: 17.6120\n",
      "Epoch 339/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 19.4372 - val_loss: 21.1610\n",
      "Epoch 340/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 19.6226 - val_loss: 18.1054\n",
      "Epoch 341/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 19.1011 - val_loss: 17.6542\n",
      "Epoch 342/500\n",
      "323/323 [==============================] - 0s 57us/step - loss: 19.0414 - val_loss: 17.6236\n",
      "Epoch 343/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 20.3654 - val_loss: 17.4325\n",
      "Epoch 344/500\n",
      "323/323 [==============================] - 0s 63us/step - loss: 19.1355 - val_loss: 21.6049\n",
      "Epoch 345/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 20.5203 - val_loss: 17.4549\n",
      "Epoch 346/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 19.0285 - val_loss: 24.3003\n",
      "Epoch 347/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 19.4951 - val_loss: 17.2359\n",
      "Epoch 348/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 20.9051 - val_loss: 18.9317\n",
      "Epoch 349/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 20.5532 - val_loss: 17.2863\n",
      "Epoch 350/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 19.1312 - val_loss: 18.2240\n",
      "Epoch 351/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 19.6710 - val_loss: 30.2704\n",
      "Epoch 352/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 22.9744 - val_loss: 17.0594\n",
      "Epoch 353/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 19.1563 - val_loss: 17.4799\n",
      "Epoch 354/500\n",
      "323/323 [==============================] - 0s 27us/step - loss: 18.8665 - val_loss: 18.8846\n",
      "Epoch 355/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 19.0383 - val_loss: 17.9453\n",
      "Epoch 356/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.7544 - val_loss: 20.0259\n",
      "Epoch 357/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 22.5339 - val_loss: 38.8934\n",
      "Epoch 358/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 28.9561 - val_loss: 21.1131\n",
      "Epoch 359/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 19.7323 - val_loss: 19.9203\n",
      "Epoch 360/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 19.2782 - val_loss: 33.0615\n",
      "Epoch 361/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 32.5901 - val_loss: 18.3507\n",
      "Epoch 362/500\n",
      "323/323 [==============================] - 0s 25us/step - loss: 19.0810 - val_loss: 17.3902\n",
      "Epoch 363/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 19.3648 - val_loss: 17.6279\n",
      "Epoch 364/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 20.0548 - val_loss: 22.5816\n",
      "Epoch 365/500\n",
      "323/323 [==============================] - 0s 24us/step - loss: 21.2978 - val_loss: 17.4253\n",
      "Epoch 366/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 18.9033 - val_loss: 29.5528\n",
      "Epoch 367/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 26.5421 - val_loss: 17.4445\n",
      "Epoch 368/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 18.7166 - val_loss: 17.2922\n",
      "Epoch 369/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 18.7019 - val_loss: 17.5088\n",
      "Epoch 370/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 19.8659 - val_loss: 17.4450\n",
      "Epoch 371/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 20.3099 - val_loss: 23.3120\n",
      "Epoch 372/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 20.4826 - val_loss: 37.2053\n",
      "Epoch 373/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 32.2436 - val_loss: 21.1066\n",
      "Epoch 374/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 19.9065 - val_loss: 17.5886\n",
      "Epoch 375/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 18.5714 - val_loss: 19.3574\n",
      "Epoch 376/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 20.7201 - val_loss: 17.1579\n",
      "Epoch 377/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 18.4265 - val_loss: 18.0331\n",
      "Epoch 378/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 18.6118 - val_loss: 17.8897\n",
      "Epoch 379/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 20.9395 - val_loss: 18.7105\n",
      "Epoch 380/500\n",
      "323/323 [==============================] - 0s 54us/step - loss: 18.7005 - val_loss: 32.3961\n",
      "Epoch 381/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 26.8578 - val_loss: 18.2564\n",
      "Epoch 382/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 18.7379 - val_loss: 18.0580\n",
      "Epoch 383/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 19.8438 - val_loss: 17.4812\n",
      "Epoch 384/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 20.4164 - val_loss: 16.8006\n",
      "Epoch 385/500\n",
      "323/323 [==============================] - 0s 55us/step - loss: 18.9344 - val_loss: 17.5187\n",
      "Epoch 386/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 18.5508 - val_loss: 21.0377\n",
      "Epoch 387/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 22.1154 - val_loss: 17.5129\n",
      "Epoch 388/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 18.6243 - val_loss: 18.5102\n",
      "Epoch 389/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 18.4711 - val_loss: 17.3585\n",
      "Epoch 390/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 18.5077 - val_loss: 17.1250\n",
      "Epoch 391/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 19.5698 - val_loss: 17.6257\n",
      "Epoch 392/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 18.8000 - val_loss: 22.9125\n",
      "Epoch 393/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 25.4739 - val_loss: 34.4927\n",
      "Epoch 394/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 22.9087 - val_loss: 22.6474\n",
      "Epoch 395/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 22.0307 - val_loss: 21.1013\n",
      "Epoch 396/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 18.9756 - val_loss: 18.1291\n",
      "Epoch 397/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 19.1838 - val_loss: 20.0704\n",
      "Epoch 398/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 19.8754 - val_loss: 24.5147\n",
      "Epoch 399/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 21.7615 - val_loss: 17.2224\n",
      "Epoch 400/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 18.6170 - val_loss: 19.3106\n",
      "Epoch 401/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 19.1293 - val_loss: 18.7143\n",
      "Epoch 402/500\n",
      "323/323 [==============================] - 0s 25us/step - loss: 19.8840 - val_loss: 18.7962\n",
      "Epoch 403/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 20.5713 - val_loss: 23.9295\n",
      "Epoch 404/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 20.1637 - val_loss: 22.8854\n",
      "Epoch 405/500\n",
      "323/323 [==============================] - 0s 49us/step - loss: 22.1361 - val_loss: 22.5859\n",
      "Epoch 406/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 21.9032 - val_loss: 22.1773\n",
      "Epoch 407/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 29.1713 - val_loss: 17.6005\n",
      "Epoch 408/500\n",
      "323/323 [==============================] - 0s 24us/step - loss: 18.0692 - val_loss: 17.4133\n",
      "Epoch 409/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 18.3145 - val_loss: 17.9609\n",
      "Epoch 410/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 18.8076 - val_loss: 22.3131\n",
      "Epoch 411/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 20.3014 - val_loss: 17.0134\n",
      "Epoch 412/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 17.9539 - val_loss: 18.0330\n",
      "Epoch 413/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.0678 - val_loss: 16.9079\n",
      "Epoch 414/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 18.2537 - val_loss: 19.2610\n",
      "Epoch 415/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 18.3441 - val_loss: 17.4707\n",
      "Epoch 416/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 18.6235 - val_loss: 21.0934\n",
      "Epoch 417/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 18.8841 - val_loss: 17.0228\n",
      "Epoch 418/500\n",
      "323/323 [==============================] - 0s 95us/step - loss: 17.9169 - val_loss: 17.2614\n",
      "Epoch 419/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 18.7260 - val_loss: 23.2807\n",
      "Epoch 420/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 22.9400 - val_loss: 16.7917\n",
      "Epoch 421/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 18.4541 - val_loss: 17.0811\n",
      "Epoch 422/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 17.9222 - val_loss: 19.2158\n",
      "Epoch 423/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 18.2755 - val_loss: 21.8178\n",
      "Epoch 424/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 20.1237 - val_loss: 18.6369\n",
      "Epoch 425/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 18.1702 - val_loss: 17.6793\n",
      "Epoch 426/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 17.8836 - val_loss: 16.9596\n",
      "Epoch 427/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 18.0142 - val_loss: 16.9030\n",
      "Epoch 428/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 17.9953 - val_loss: 20.5947\n",
      "Epoch 429/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 19.2695 - val_loss: 17.9848\n",
      "Epoch 430/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 18.1533 - val_loss: 20.4078\n",
      "Epoch 431/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 18.2872 - val_loss: 17.4906\n",
      "Epoch 432/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 18.2056 - val_loss: 20.8881\n",
      "Epoch 433/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 19.6669 - val_loss: 17.0019\n",
      "Epoch 434/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 17.8373 - val_loss: 16.9766\n",
      "Epoch 435/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 17.9108 - val_loss: 16.9783\n",
      "Epoch 436/500\n",
      "323/323 [==============================] - 0s 41us/step - loss: 18.3951 - val_loss: 25.1291\n",
      "Epoch 437/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 19.8552 - val_loss: 16.8976\n",
      "Epoch 438/500\n",
      "323/323 [==============================] - 0s 26us/step - loss: 18.0204 - val_loss: 17.6159\n",
      "Epoch 439/500\n",
      "323/323 [==============================] - 0s 53us/step - loss: 17.8576 - val_loss: 20.8250\n",
      "Epoch 440/500\n",
      "323/323 [==============================] - 0s 50us/step - loss: 20.1410 - val_loss: 20.3936\n",
      "Epoch 441/500\n",
      "323/323 [==============================] - 0s 40us/step - loss: 19.8115 - val_loss: 20.3877\n",
      "Epoch 442/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 18.1271 - val_loss: 17.4181\n",
      "Epoch 443/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 18.5381 - val_loss: 49.4101\n",
      "Epoch 444/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 34.1108 - val_loss: 19.2643\n",
      "Epoch 445/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 19.4367 - val_loss: 18.5014\n",
      "Epoch 446/500\n",
      "323/323 [==============================] - 0s 52us/step - loss: 17.7826 - val_loss: 17.4500\n",
      "Epoch 447/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.1420 - val_loss: 23.9730\n",
      "Epoch 448/500\n",
      "323/323 [==============================] - ETA: 0s - loss: 28.63 - 0s 43us/step - loss: 19.5042 - val_loss: 17.3272\n",
      "Epoch 449/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 17.8720 - val_loss: 22.9179\n",
      "Epoch 450/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 23.0821 - val_loss: 16.9820\n",
      "Epoch 451/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 17.5666 - val_loss: 16.9020\n",
      "Epoch 452/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 17.5429 - val_loss: 17.4263\n",
      "Epoch 453/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.6941 - val_loss: 19.3952\n",
      "Epoch 454/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 18.8628 - val_loss: 17.0565\n",
      "Epoch 455/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 18.8603 - val_loss: 17.2737\n",
      "Epoch 456/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 18.0180 - val_loss: 19.0261\n",
      "Epoch 457/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 17.6758 - val_loss: 27.1751\n",
      "Epoch 458/500\n",
      "323/323 [==============================] - 0s 35us/step - loss: 21.5966 - val_loss: 22.8611\n",
      "Epoch 459/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 18.5208 - val_loss: 16.6260\n",
      "Epoch 460/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 17.5824 - val_loss: 18.4306\n",
      "Epoch 461/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 20.1840 - val_loss: 16.4493\n",
      "Epoch 462/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 17.4337 - val_loss: 17.0349\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 45us/step - loss: 19.0735 - val_loss: 20.5091\n",
      "Epoch 464/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 18.5354 - val_loss: 17.0350\n",
      "Epoch 465/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 17.6212 - val_loss: 16.9479\n",
      "Epoch 466/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 17.9397 - val_loss: 23.3887\n",
      "Epoch 467/500\n",
      "323/323 [==============================] - 0s 30us/step - loss: 20.9414 - val_loss: 16.7255\n",
      "Epoch 468/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 17.3889 - val_loss: 27.4363\n",
      "Epoch 469/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 23.3099 - val_loss: 17.3380\n",
      "Epoch 470/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 18.5178 - val_loss: 16.6044\n",
      "Epoch 471/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 17.6854 - val_loss: 16.6600\n",
      "Epoch 472/500\n",
      "323/323 [==============================] - 0s 29us/step - loss: 18.6782 - val_loss: 27.2891\n",
      "Epoch 473/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 20.8120 - val_loss: 25.6001\n",
      "Epoch 474/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.2615 - val_loss: 19.9511\n",
      "Epoch 475/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 18.0620 - val_loss: 17.9420\n",
      "Epoch 476/500\n",
      "323/323 [==============================] - 0s 31us/step - loss: 17.7469 - val_loss: 17.8247\n",
      "Epoch 477/500\n",
      "323/323 [==============================] - 0s 44us/step - loss: 18.8162 - val_loss: 16.6810\n",
      "Epoch 478/500\n",
      "323/323 [==============================] - 0s 37us/step - loss: 17.4527 - val_loss: 20.2072\n",
      "Epoch 479/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 20.7573 - val_loss: 16.3885\n",
      "Epoch 480/500\n",
      "323/323 [==============================] - 0s 28us/step - loss: 17.6155 - val_loss: 19.1800\n",
      "Epoch 481/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 18.4662 - val_loss: 17.4598\n",
      "Epoch 482/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 17.7262 - val_loss: 20.0678\n",
      "Epoch 483/500\n",
      "323/323 [==============================] - 0s 33us/step - loss: 18.0178 - val_loss: 20.5060\n",
      "Epoch 484/500\n",
      "323/323 [==============================] - 0s 38us/step - loss: 17.8369 - val_loss: 16.5725\n",
      "Epoch 485/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 17.2974 - val_loss: 17.2454\n",
      "Epoch 486/500\n",
      "323/323 [==============================] - 0s 51us/step - loss: 17.9161 - val_loss: 17.1208\n",
      "Epoch 487/500\n",
      "323/323 [==============================] - 0s 32us/step - loss: 19.1637 - val_loss: 19.4252\n",
      "Epoch 488/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 19.3706 - val_loss: 16.3672\n",
      "Epoch 489/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 20.0070 - val_loss: 20.4985\n",
      "Epoch 490/500\n",
      "323/323 [==============================] - 0s 42us/step - loss: 17.5431 - val_loss: 17.3514\n",
      "Epoch 491/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 18.4436 - val_loss: 20.6867\n",
      "Epoch 492/500\n",
      "323/323 [==============================] - 0s 55us/step - loss: 20.6865 - val_loss: 20.2001\n",
      "Epoch 493/500\n",
      "323/323 [==============================] - 0s 45us/step - loss: 22.1698 - val_loss: 17.9564\n",
      "Epoch 494/500\n",
      "323/323 [==============================] - 0s 43us/step - loss: 17.9545 - val_loss: 18.4344\n",
      "Epoch 495/500\n",
      "323/323 [==============================] - 0s 39us/step - loss: 21.2293 - val_loss: 17.6715\n",
      "Epoch 496/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 20.1657 - val_loss: 17.0361\n",
      "Epoch 497/500\n",
      "323/323 [==============================] - 0s 34us/step - loss: 18.7880 - val_loss: 16.9937\n",
      "Epoch 498/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 17.2310 - val_loss: 20.5458\n",
      "Epoch 499/500\n",
      "323/323 [==============================] - 0s 47us/step - loss: 18.5636 - val_loss: 19.6472\n",
      "Epoch 500/500\n",
      "323/323 [==============================] - 0s 36us/step - loss: 18.2999 - val_loss: 19.6568\n"
     ]
    }
   ],
   "source": [
    "Nin = 13\n",
    "Nh = 5\n",
    "Nout = 1\n",
    "\n",
    "model = ANN(Nin, Nh, Nout)\n",
    "(X_train, Y_train), (X_test, Y_test) = Data_func()\n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 180us/step\n",
      "\n",
      "Test Loss -> 30.312361\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('\\nTest Loss -> {:2f}'.format(performance_test))\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
