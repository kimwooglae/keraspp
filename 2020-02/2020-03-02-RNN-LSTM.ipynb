{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        (x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "        x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "        x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_LSTM(models.Model):\n",
    "    def __init__(self, max_features, maxlen):\n",
    "        x = layers.Input((maxlen,))\n",
    "        h = layers.Embedding(max_features, 128)(x)\n",
    "        h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "        y = layers.Dense(1, activation='sigmoid')(h)\n",
    "        super().__init__(x, y)\n",
    "        \n",
    "        self.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        self.data = Data(max_features, maxlen)\n",
    "        self.model = RNN_LSTM(max_features, maxlen)\n",
    "        \n",
    "    def run(self, epochs=25, batch_size=32):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        print('Training stage')\n",
    "        print('==================')\n",
    "        model.fit(data.x_train, data.y_train, batch_size=batch_size, epochs=epochs, validation_data=(data.x_test, data.y_test))\n",
    "        score, acc = model.evaluate(data.x_test, data.y_test, batch_size=batch_size)\n",
    "        print('Test performance: accuracy={0}, loss={1}'.format(acc, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stage\n",
      "==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.4505 - accuracy: 0.7923 - val_loss: 0.3744 - val_accuracy: 0.8355\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.2997 - accuracy: 0.8763 - val_loss: 0.3765 - val_accuracy: 0.8387\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.2202 - accuracy: 0.9151 - val_loss: 0.4064 - val_accuracy: 0.8321\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.1515 - accuracy: 0.9438 - val_loss: 0.5088 - val_accuracy: 0.8228\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.1182 - accuracy: 0.9586 - val_loss: 0.5231 - val_accuracy: 0.8192\n",
      "Epoch 6/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0848 - accuracy: 0.9702 - val_loss: 0.5833 - val_accuracy: 0.8150\n",
      "Epoch 7/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0640 - accuracy: 0.9778 - val_loss: 0.6842 - val_accuracy: 0.8197\n",
      "Epoch 8/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.7094 - val_accuracy: 0.8161\n",
      "Epoch 9/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.8619 - val_accuracy: 0.8162\n",
      "Epoch 10/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.9136 - val_accuracy: 0.8126\n",
      "Epoch 11/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.9154 - val_accuracy: 0.8129\n",
      "Epoch 12/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 1.0076 - val_accuracy: 0.8070\n",
      "Epoch 13/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 1.0162 - val_accuracy: 0.8090\n",
      "Epoch 14/25\n",
      "25000/25000 [==============================] - 56s 2ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 1.1273 - val_accuracy: 0.8089\n",
      "Epoch 15/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 1.1958 - val_accuracy: 0.8014\n",
      "Epoch 16/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.1408 - val_accuracy: 0.8102\n",
      "Epoch 17/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.2113 - val_accuracy: 0.8138\n",
      "Epoch 18/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.1234 - val_accuracy: 0.8095\n",
      "Epoch 19/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 1.2905 - val_accuracy: 0.8119\n",
      "Epoch 20/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.2556 - val_accuracy: 0.7988\n",
      "Epoch 21/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 1.3327 - val_accuracy: 0.8086\n",
      "Epoch 22/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.2880 - val_accuracy: 0.8058\n",
      "Epoch 23/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.3088 - val_accuracy: 0.8010\n",
      "Epoch 24/25\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 1.2704 - val_accuracy: 0.8042\n",
      "Epoch 25/25\n",
      "25000/25000 [==============================] - 54s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.4646 - val_accuracy: 0.8020\n",
      "25000/25000 [==============================] - 10s 384us/step\n",
      "Test performance: accuracy=0.8020399808883667, loss=1.4645594865012168\n"
     ]
    }
   ],
   "source": [
    "m = Machine()\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=1000000)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    19,   178,    32],\n",
       "       [    0,     0,     0, ...,    16,   145,    95],\n",
       "       [    0,     0,     0, ...,     7,   129,   113],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     4,  3586, 22459],\n",
       "       [    0,     0,     0, ...,    12,     9,    23],\n",
       "       [    0,     0,     0, ...,   204,   131,     9]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=3000)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
