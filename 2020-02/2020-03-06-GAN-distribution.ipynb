{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras.layers import Dense, Conv1D, Reshape, Flatten, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, mu, sigma, ni_D):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.ni_D = ni_D\n",
    "        #self.real_sample = lambda n_batch: np.random.normal(mu, sigma, (n_batch, ni_D))\n",
    "        #self.in_sample = lambda n_batch: np.random.rand(n_batch, ni_D)\n",
    "\n",
    "    def real_sample(self, n_batch):\n",
    "        return np.random.normal(self.mu, self.sigma, (n_batch, self.ni_D))\n",
    "\n",
    "    def in_sample(self, n_batch):\n",
    "        return np.random.rand(n_batch, self.ni_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, n_batch=10, ni_D=100):\n",
    "        data_mean = 4\n",
    "        data_stddev = 1.25\n",
    "\n",
    "        self.n_iter_D = 1\n",
    "        self.n_iter_G = 5\n",
    "\n",
    "        self.data = Data(data_mean, data_stddev, ni_D)\n",
    "        self.gan = GAN(ni_D=ni_D, nh_D=50, nh_G=50)\n",
    "        self.n_batch = n_batch\n",
    "\n",
    "    def train_D(self):\n",
    "        gan = self.gan\n",
    "        n_batch = self.n_batch\n",
    "        data = self.data\n",
    "        Real = data.real_sample(n_batch)\n",
    "        Z = data.in_sample(n_batch)\n",
    "\n",
    "        Gen = gan.G.predict(Z)\n",
    "        #gan.D.trainable = True\n",
    "        print('train_D')\n",
    "        gan.D_train_on_batch(Real, Gen)\n",
    "\n",
    "    def train_GD(self):\n",
    "        gan = self.gan\n",
    "        n_batch = self.n_batch\n",
    "        data = self.data\n",
    "        Z = data.in_sample(n_batch)\n",
    "\n",
    "        gan.D.trainable = False\n",
    "        print('train_GD')\n",
    "        gan.GD_train_on_batch(Z)\n",
    "\n",
    "    def train_each(self, epoch):\n",
    "        print('train_each - 0:', epoch)\n",
    "        for it in range(self.n_iter_D):\n",
    "            print('train_each - 1:', epoch)\n",
    "            self.train_D()\n",
    "        for it in range(self.n_iter_G):\n",
    "            print('train_each - 2:', epoch)\n",
    "            self.train_GD()\n",
    "\n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.train_each(epoch)\n",
    "\n",
    "    def test(self, n_test):\n",
    "        gan = self.gan\n",
    "        data = self.data\n",
    "        Z = data.in_sample(n_test)\n",
    "        Gen = gan.G.predict(Z)\n",
    "        return Gen, Z\n",
    "\n",
    "    def show_hist(self, Real, Gen, Z):\n",
    "        plt.hist(Real.reshape(-1), histtype='step', label='Real')\n",
    "        plt.hist(Gen.reshape(-1), histtype='step', label='Generated')\n",
    "        plt.hist(Z.reshape(-1), histtype='step', label='Input')\n",
    "        plt.legend(loc=0)\n",
    "\n",
    "    def test_and_show(self, n_test):\n",
    "        data = self.data\n",
    "        Gen, Z = self.test(n_test)\n",
    "        Real = data.real_sample(n_test)\n",
    "        self.show_hist(Real, Gen, Z)\n",
    "        self.print_stat(Real, Gen)\n",
    "\n",
    "    def run_epochs(self, epochs, n_test):\n",
    "        self.train(epochs)\n",
    "        self.test_and_show(n_test)\n",
    "\n",
    "    def run(self, n_repeat=200, n_show=200, n_test=100):\n",
    "        for ii in range(n_repeat):\n",
    "            print('Stage', ii, '(Epoch: {})'.format(ii * n_show))\n",
    "            self.run_epochs(n_show, n_test)\n",
    "            plt.show()\n",
    "\n",
    "    def print_stat(self, Real, Gen):\n",
    "        def stat(d):\n",
    "            return (np.mean(d), np.std(d))\n",
    "        print('Mean and Std of Real:', stat(Real))\n",
    "        print('Mean and Std of Gen:', stat(Gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_decorate(x):\n",
    "    m = K.mean(x, axis=-1, keepdims=True)\n",
    "    d = K.square(x - m)\n",
    "    return K.concatenate([x,d], axis=-1)\n",
    "\n",
    "def add_decorate_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(input_shape) == 2\n",
    "    shape[1] *= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "lr = 2e-4\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "def model_compile(model):\n",
    "    return model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, ni_D, nh_D, nh_G):\n",
    "        self.ni_D = ni_D\n",
    "        self.nh_D = nh_D\n",
    "        self.nh_G = nh_G\n",
    "        \n",
    "        self.D = self.gen_D()\n",
    "        self.G = self.gen_G()\n",
    "        self.GD = self.make_GD()\n",
    "    \n",
    "    def gen_D(self):\n",
    "        ni_D = self.ni_D\n",
    "        nh_D = self.nh_D\n",
    "        \n",
    "        D = models.Sequential()\n",
    "        D.add(Lambda(add_decorate, output_shape=add_decorate_shape, input_shape=(ni_D,)))\n",
    "        \n",
    "        D.add(Dense(nh_D, activation='relu'))\n",
    "        D.add(Dense(nh_D, activation='relu'))\n",
    "        D.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model_compile(D)\n",
    "\n",
    "        print('D.summary()')\n",
    "        D.summary()\n",
    "        return D\n",
    "    \n",
    "    def gen_G(self):\n",
    "        ni_D = self.ni_D\n",
    "        nh_G = self.nh_G\n",
    "        \n",
    "        G = models.Sequential()\n",
    "        G.add(Reshape((ni_D, 1), input_shape=(ni_D,)))\n",
    "        G.add(Conv1D(nh_G, 1, activation='relu'))\n",
    "        G.add(Conv1D(nh_G, 1, activation='sigmoid'))\n",
    "        G.add(Conv1D(1, 1))\n",
    "        G.add(Flatten())\n",
    "        \n",
    "        model_compile(G)\n",
    "        \n",
    "        print('G.summary()')\n",
    "        G.summary()\n",
    "        return G\n",
    "    \n",
    "    def make_GD(self):\n",
    "        G, D = self.G, self.D\n",
    "        GD = models.Sequential()\n",
    "        GD.add(G)\n",
    "        GD.add(D)\n",
    "        D.trainable = False\n",
    "        model_compile(GD)\n",
    "        print('GD.summary()')\n",
    "        GD.summary()\n",
    "        D.trainable = True\n",
    "        return GD\n",
    "    \n",
    "    def D_train_on_batch(self, Real, Gen):\n",
    "        D = self.D\n",
    "        X = np.concatenate([Real, Gen], axis=0)\n",
    "        y = np.array([1]*Real.shape[0] + [0]*Gen.shape[0])\n",
    "        \n",
    "        print('X.shape',X.shape)\n",
    "        print('y.shape',y.shape)\n",
    "        print(X)        \n",
    "        print(y)\n",
    "        D.train_on_batch(X, y)\n",
    "#        D.fit(X,y)\n",
    "        \n",
    "    def GD_train_on_batch(self, Z):\n",
    "        GD = self.GD\n",
    "        y = np.array([1]*Z.shape[0])\n",
    "        print('Z.shape',Z.shape)\n",
    "        print('y.shape',y.shape)\n",
    "        print(Z)        \n",
    "        print(y)\n",
    "        \n",
    "        \n",
    "        GD.train_on_batch(Z, y)\n",
    "#        GD.fit(Z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.summary()\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_21 (Lambda)           (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,651\n",
      "Trainable params: 12,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "G.summary()\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_21 (Reshape)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 100, 50)           100       \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 100, 50)           2550      \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 100, 1)            51        \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,701\n",
      "Trainable params: 2,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "GD.summary()\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_61 (Sequential)   (None, 100)               2701      \n",
      "_________________________________________________________________\n",
      "sequential_60 (Sequential)   (None, 1)                 12651     \n",
      "=================================================================\n",
      "Total params: 15,352\n",
      "Trainable params: 2,701\n",
      "Non-trainable params: 12,651\n",
      "_________________________________________________________________\n",
      "Stage 0 (Epoch: 0)\n",
      "train_each - 0: 0\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[1.6115738  3.68554335 3.81330076 5.12307976 3.17073481 1.21893706\n",
      "  4.66422918 4.66739717 4.73967518 4.77657276 1.23164435 4.69515429\n",
      "  2.80592926 4.89195489 3.43530294 3.95730683 3.94564269 4.1635175\n",
      "  3.7244128  6.05779521 2.92534682 3.20353356 6.23430495 4.38114432\n",
      "  3.37693023 3.29304307 3.03324319 2.66779919 4.46709245 2.91299305\n",
      "  4.63518499 4.86466786 3.15693127 3.17110011 3.74693316 5.06657926\n",
      "  4.14233266 3.91221266 4.33208275 5.53890435 5.32732969 2.98479991\n",
      "  2.84214243 3.17217623 6.48510209 3.34291013 4.44041077 2.83075395\n",
      "  3.29249337 4.21597933 3.057649   4.07705815 2.56886245 2.29590242\n",
      "  5.00754674 4.66373472 5.32824308 3.16290319 2.91970187 5.9507628\n",
      "  6.0792529  3.06637128 3.98152604 4.79809295 4.61983354 5.70151078\n",
      "  5.45625531 3.74826459 2.8865483  3.92255707 5.25135075 3.9388843\n",
      "  4.02556092 1.36377895 2.8965842  3.91179814 5.1755243  3.43918674\n",
      "  4.83293549 4.20484978 6.57670335 5.06824528 4.58973097 2.75044132\n",
      "  4.12087133 3.71499653 2.91764866 2.3253085  3.18105764 4.87740158\n",
      "  0.88679973 3.018851   4.70569109 5.03751598 4.81532788 5.23689741\n",
      "  3.98775294 3.88381578 4.53068    4.42299909]\n",
      " [0.19494955 0.19693594 0.2024101  0.19087069 0.19875164 0.20120448\n",
      "  0.19861317 0.19187589 0.18944475 0.18769448 0.19008113 0.19301571\n",
      "  0.19136752 0.18968876 0.20185889 0.19884238 0.20058419 0.18780948\n",
      "  0.1888012  0.20064691 0.20063017 0.18852572 0.19762841 0.20048471\n",
      "  0.20031196 0.1980392  0.20076968 0.19601208 0.19536692 0.19199979\n",
      "  0.19387543 0.18760493 0.19120334 0.19257836 0.18846272 0.18925309\n",
      "  0.19427061 0.19546685 0.20217648 0.20170952 0.19654347 0.20052053\n",
      "  0.1969095  0.19390583 0.1978257  0.19347605 0.19205846 0.20295356\n",
      "  0.19943625 0.18918766 0.20102195 0.19238533 0.19667292 0.19895425\n",
      "  0.19807388 0.19122396 0.19327419 0.19824298 0.20211394 0.20150952\n",
      "  0.18931195 0.19695082 0.19174731 0.19687322 0.19714873 0.2021479\n",
      "  0.20049213 0.19412474 0.19322793 0.18772639 0.19874099 0.18798214\n",
      "  0.20091169 0.18977384 0.20156354 0.19473332 0.20150349 0.19376251\n",
      "  0.19076519 0.19638108 0.20293398 0.19417058 0.1983048  0.19588578\n",
      "  0.19320001 0.19777793 0.20118442 0.20302524 0.20029907 0.2005477\n",
      "  0.20267247 0.20022303 0.20262063 0.20002447 0.19098203 0.19750324\n",
      "  0.19945133 0.19311778 0.19825889 0.19381201]]\n",
      "[1 0]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.8076375  0.19192194 0.73589509 0.50263454 0.61741948 0.72831315\n",
      "  0.77269558 0.33456249 0.7831139  0.69284672 0.10156438 0.04294677\n",
      "  0.15850871 0.95757915 0.85688557 0.05137949 0.94399454 0.50167562\n",
      "  0.75685492 0.36114487 0.50738323 0.4493875  0.23009739 0.33701986\n",
      "  0.54530931 0.05878214 0.92358766 0.16319248 0.94999601 0.40859381\n",
      "  0.07287773 0.08810345 0.65177135 0.04509284 0.62060013 0.82122262\n",
      "  0.33908208 0.34347736 0.76359353 0.5599778  0.61565661 0.21738427\n",
      "  0.39211333 0.11425694 0.36811194 0.13351254 0.40527332 0.89970182\n",
      "  0.91547152 0.84653051 0.32529778 0.34765068 0.8153729  0.24135238\n",
      "  0.58430889 0.77596354 0.9947459  0.79161138 0.76985792 0.44375931\n",
      "  0.60574113 0.56768834 0.73041625 0.23039322 0.84719635 0.86173056\n",
      "  0.71819536 0.29190651 0.52545876 0.84161659 0.92558634 0.62043811\n",
      "  0.52910639 0.84637435 0.9625692  0.19179039 0.9664728  0.0745468\n",
      "  0.17940611 0.75075616 0.46410198 0.77726862 0.60636506 0.57013839\n",
      "  0.56595331 0.17192335 0.85185303 0.96823649 0.35634791 0.54361098\n",
      "  0.046261   0.37448351 0.33561952 0.03841267 0.42272569 0.11692021\n",
      "  0.36239009 0.76853137 0.92722472 0.75991034]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.94971224 0.2868091  0.37049319 0.0748414  0.07687674 0.65508156\n",
      "  0.06148513 0.29415298 0.99536575 0.69328121 0.57697559 0.35205949\n",
      "  0.80853466 0.81962621 0.40981752 0.05772145 0.61846277 0.96407379\n",
      "  0.20991789 0.29508027 0.47948306 0.20899282 0.74351953 0.11144919\n",
      "  0.3761787  0.87061994 0.74155058 0.28966224 0.00530009 0.45453376\n",
      "  0.47503413 0.82176068 0.14229854 0.52976773 0.01383213 0.60017754\n",
      "  0.15057264 0.08403047 0.40943945 0.93859948 0.61057841 0.63895506\n",
      "  0.58667368 0.64877664 0.87033133 0.64284508 0.5645934  0.59205753\n",
      "  0.79524829 0.08390189 0.19056642 0.54807762 0.42798563 0.70802083\n",
      "  0.91893143 0.69610294 0.31361693 0.29204527 0.32081307 0.38384462\n",
      "  0.75814028 0.85776666 0.75363359 0.55180452 0.60578717 0.30489832\n",
      "  0.14508299 0.33930812 0.77611438 0.62795211 0.62948904 0.41489591\n",
      "  0.91972178 0.43482622 0.00113003 0.40008119 0.71173531 0.32226556\n",
      "  0.30135323 0.2308037  0.03794535 0.24611653 0.43264662 0.45054002\n",
      "  0.41300929 0.1032598  0.70703541 0.17423698 0.15612994 0.69251105\n",
      "  0.72606762 0.74499755 0.92670149 0.17476662 0.87932834 0.03434384\n",
      "  0.13176923 0.0518727  0.24980068 0.15711406]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.19425012 0.19516799 0.13413878 0.73546677 0.77919368 0.28972457\n",
      "  0.41153432 0.55825914 0.3145215  0.57834712 0.82467373 0.8361738\n",
      "  0.88323439 0.49194391 0.01127936 0.35614088 0.48466002 0.82470772\n",
      "  0.67232975 0.91501443 0.82012198 0.79517263 0.92258627 0.02442407\n",
      "  0.51507461 0.03689852 0.71700079 0.01128383 0.60407493 0.33945697\n",
      "  0.15589004 0.53578942 0.58533173 0.64254719 0.56904613 0.07237116\n",
      "  0.26419528 0.4201661  0.07156314 0.06717623 0.42607139 0.28854434\n",
      "  0.63182369 0.1375674  0.21594068 0.55890859 0.0220952  0.24139146\n",
      "  0.42892394 0.94591731 0.76579338 0.68562486 0.30515625 0.65126809\n",
      "  0.32779505 0.34542748 0.98410529 0.36828307 0.94415459 0.14632733\n",
      "  0.95628199 0.79138474 0.11420367 0.8590907  0.09103421 0.81173539\n",
      "  0.94481111 0.3423974  0.88571241 0.65711686 0.64060105 0.31322702\n",
      "  0.05101176 0.80660818 0.0330836  0.90977173 0.55484305 0.28486588\n",
      "  0.1616409  0.50914522 0.80526649 0.44879148 0.5038604  0.76908311\n",
      "  0.60333527 0.67895252 0.08127922 0.80051546 0.09078482 0.41113175\n",
      "  0.92467024 0.16544611 0.93824276 0.27822088 0.1996836  0.5170655\n",
      "  0.64210024 0.30269324 0.83943011 0.71368741]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.08839151 0.19048965 0.41009077 0.41434789 0.61472963 0.27900876\n",
      "  0.34942455 0.58256018 0.55588709 0.37553343 0.71513847 0.40890657\n",
      "  0.47314747 0.17553655 0.51802523 0.32141029 0.05255492 0.88342705\n",
      "  0.09873441 0.46907025 0.54775428 0.95144496 0.07770112 0.37656024\n",
      "  0.05514776 0.87226178 0.9494108  0.69700722 0.31256162 0.58962938\n",
      "  0.74763222 0.5141405  0.9498262  0.42559986 0.53192574 0.7384056\n",
      "  0.30011551 0.81623901 0.47367695 0.8937582  0.44816255 0.91561973\n",
      "  0.34581742 0.31678249 0.82605331 0.9814029  0.73657358 0.50717147\n",
      "  0.44100579 0.44180988 0.60957735 0.13738408 0.16238845 0.53852321\n",
      "  0.40420579 0.79788776 0.35747235 0.79720135 0.79247528 0.34391549\n",
      "  0.79179405 0.16477612 0.10113238 0.80881561 0.18015093 0.78784722\n",
      "  0.3884162  0.70133762 0.75208122 0.67500826 0.44239512 0.96788184\n",
      "  0.28979382 0.26978661 0.10044264 0.14681485 0.75167829 0.70993394\n",
      "  0.26687295 0.57804716 0.22160147 0.44681104 0.98619494 0.08209987\n",
      "  0.77297858 0.91030458 0.63600982 0.92694706 0.89177341 0.66622279\n",
      "  0.65890001 0.83124003 0.00591026 0.54322333 0.58336061 0.5282947\n",
      "  0.69544949 0.58573059 0.77584172 0.53683033]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[9.07433016e-01 9.63552126e-01 4.99414681e-01 1.39174038e-02\n",
      "  2.54076133e-02 3.17706456e-01 6.32417512e-01 1.74298765e-01\n",
      "  3.63512275e-01 9.15996773e-01 9.75375860e-01 1.58800356e-01\n",
      "  7.89411054e-01 8.51371535e-01 2.66829226e-01 3.21528971e-01\n",
      "  3.17099493e-01 8.13429386e-01 6.49081519e-01 2.70902249e-01\n",
      "  4.11688489e-01 4.54839026e-01 6.99902703e-01 6.45840979e-01\n",
      "  5.16795759e-01 4.93756828e-01 9.73910669e-02 9.93439681e-01\n",
      "  5.93649033e-01 6.81594365e-01 5.52568509e-01 4.50137895e-02\n",
      "  6.34797117e-01 5.67933633e-01 4.99748246e-01 3.12241006e-01\n",
      "  1.30856047e-01 9.89221013e-02 7.38963429e-01 9.05437355e-01\n",
      "  7.30959549e-01 3.20463006e-01 9.22575603e-01 8.19361039e-01\n",
      "  2.16482456e-01 4.57455124e-02 5.74147622e-01 8.24234282e-02\n",
      "  6.74406449e-01 4.75353853e-01 8.25092980e-01 3.74284855e-01\n",
      "  5.93144342e-01 6.04021673e-01 9.15118843e-01 2.92795132e-01\n",
      "  2.77887561e-01 6.84367906e-01 2.52227696e-01 4.94631118e-01\n",
      "  9.13309292e-01 9.40691863e-01 3.24294280e-01 1.46109237e-01\n",
      "  1.17541658e-01 1.67422506e-02 5.68899888e-01 4.14634719e-01\n",
      "  4.28753943e-01 2.99056226e-01 9.04531803e-01 3.83700800e-01\n",
      "  9.32294902e-01 6.41211063e-01 1.04293652e-01 8.09194842e-02\n",
      "  7.66075997e-01 8.08226198e-01 1.81448853e-01 2.90134618e-01\n",
      "  7.78365179e-04 3.96661417e-01 8.49841918e-01 5.89376667e-02\n",
      "  2.48105661e-01 3.90784111e-01 3.17240472e-01 4.89848594e-01\n",
      "  1.74359396e-01 9.98904347e-01 3.69822167e-01 9.46048897e-01\n",
      "  9.13331694e-01 7.30733844e-01 7.61438572e-01 4.24494517e-01\n",
      "  5.02130540e-01 2.98999394e-01 8.12040850e-03 6.80866391e-01]]\n",
      "[1]\n",
      "train_each - 0: 1\n",
      "train_each - 1: 1\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[5.10010707 3.82265378 6.50169848 5.41680096 4.00359193 6.20543768\n",
      "  3.96860825 4.55303053 3.59294481 5.53038964 2.37425722 4.53631211\n",
      "  4.02999937 3.17220823 5.06900015 4.97962639 5.76409058 3.56801232\n",
      "  5.00955287 4.20015711 3.00461391 5.43258016 5.09163664 2.33679832\n",
      "  3.51419774 3.85185125 0.29745271 3.92721162 5.12364005 3.2972285\n",
      "  4.38383911 3.28030676 5.80548608 5.15862328 7.57611732 5.57790002\n",
      "  6.36674796 3.65747496 4.92634492 4.36505257 2.48173806 5.74506453\n",
      "  2.88962236 4.24444348 3.51933524 3.18829159 4.575802   2.94016726\n",
      "  3.40707863 4.89652503 3.86353401 4.11512868 5.37987958 4.72799437\n",
      "  5.01786143 3.86399077 4.51462421 3.22828669 0.56361832 4.18380662\n",
      "  2.61289854 3.47168608 4.61167467 2.19071704 2.98158931 5.81846464\n",
      "  1.94705019 3.88675149 4.21834314 3.50152901 4.35104664 6.10259047\n",
      "  3.84902138 3.81208516 4.66726387 2.88884854 7.45274986 3.40826189\n",
      "  4.26979391 3.36608948 2.97350694 5.09893748 3.62316    5.37584563\n",
      "  2.63408941 3.85704644 1.89336486 3.57975662 4.34389997 2.93968354\n",
      "  3.89549938 4.94492547 4.64968042 4.72558065 0.937334   5.57256484\n",
      "  3.04092681 3.98635037 3.9274243  4.60137345]\n",
      " [0.22482151 0.22089025 0.21880423 0.22155422 0.22149615 0.22354504\n",
      "  0.2183671  0.21860768 0.21996024 0.2196608  0.2260754  0.21925019\n",
      "  0.22196506 0.21952531 0.2264263  0.21831913 0.22539714 0.22061533\n",
      "  0.22631997 0.22094536 0.21846551 0.22490941 0.22307643 0.22414556\n",
      "  0.22615296 0.22537427 0.2259718  0.21803457 0.21809039 0.22028033\n",
      "  0.21942052 0.21934415 0.22083662 0.22186689 0.22498979 0.21903443\n",
      "  0.22598083 0.22525589 0.21982995 0.21811222 0.22218345 0.22240278\n",
      "  0.22026825 0.2255756  0.22293723 0.2228878  0.21863879 0.22097878\n",
      "  0.22345786 0.2181126  0.22100599 0.2247785  0.22258723 0.21990965\n",
      "  0.22602418 0.22519545 0.2257112  0.22650674 0.22472228 0.22001982\n",
      "  0.22607511 0.21929826 0.22506274 0.21845858 0.22403064 0.22416247\n",
      "  0.22473052 0.21815985 0.21875708 0.222541   0.22410876 0.2194847\n",
      "  0.22238947 0.21866779 0.22311781 0.21869211 0.21834841 0.2201739\n",
      "  0.22258466 0.22084425 0.21818532 0.22145952 0.22027737 0.22016141\n",
      "  0.22566085 0.21883039 0.21902563 0.22302438 0.22236639 0.22225106\n",
      "  0.22353455 0.22433734 0.21985063 0.22645606 0.22076426 0.21867003\n",
      "  0.2183933  0.22298557 0.21806207 0.21970679]]\n",
      "[1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": " Error while reading resource variable _AnonymousVar873 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar873/N10tensorflow3VarE does not exist.\n\t [[node mul_807/ReadVariableOp (defined at /home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_206828]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-e69b69f01a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#keras.backend.get_session().run(tf.global_variables_initializer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mni_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_show\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-eaf59d7838bc>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_repeat, n_show, n_test)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(Epoch: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_show\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-eaf59d7838bc>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, epochs, n_test)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_and_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-eaf59d7838bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-eaf59d7838bc>\u001b[0m in \u001b[0;36mtrain_each\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_each - 1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_each - 2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-eaf59d7838bc>\u001b[0m in \u001b[0;36mtrain_D\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#gan.D.trainable = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_train_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-7eba22c560a4>\u001b[0m in \u001b[0;36mD_train_on_batch\u001b[0;34m(self, Real, Gen)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;31m#        D.fit(X,y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable _AnonymousVar873 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar873/N10tensorflow3VarE does not exist.\n\t [[node mul_807/ReadVariableOp (defined at /home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_206828]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.python.keras.backend as K\n",
    "#sess = K.get_session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "machine = Machine(n_batch=1, ni_D=100)\n",
    "machine.run(n_repeat=200, n_show=200, n_test=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
