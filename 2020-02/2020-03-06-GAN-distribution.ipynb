{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras.layers import Dense, Conv1D, Reshape, Flatten, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, mu, sigma, ni_D):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.ni_D = ni_D\n",
    "        #self.real_sample = lambda n_batch: np.random.normal(mu, sigma, (n_batch, ni_D))\n",
    "        #self.in_sample = lambda n_batch: np.random.rand(n_batch, ni_D)\n",
    "\n",
    "    def real_sample(self, n_batch):\n",
    "        return np.random.normal(self.mu, self.sigma, (n_batch, self.ni_D))\n",
    "\n",
    "    def in_sample(self, n_batch):\n",
    "        return np.random.rand(n_batch, self.ni_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, n_batch=10, ni_D=100):\n",
    "        data_mean = 4\n",
    "        data_stddev = 1.25\n",
    "\n",
    "        self.n_iter_D = 5\n",
    "        self.n_iter_G = 5\n",
    "\n",
    "        self.data = Data(data_mean, data_stddev, ni_D)\n",
    "        self.gan = GAN(ni_D=ni_D, nh_D=50, nh_G=50)\n",
    "        self.n_batch = n_batch\n",
    "\n",
    "    def train_D(self):\n",
    "        gan = self.gan\n",
    "        n_batch = self.n_batch\n",
    "        data = self.data\n",
    "        Real = data.real_sample(n_batch)\n",
    "        Z = data.in_sample(n_batch)\n",
    "\n",
    "        Gen = gan.G.predict(Z)\n",
    "        gan.D.trainable = True\n",
    "        print('train_D')\n",
    "        gan.D_train_on_batch(Real, Gen)\n",
    "\n",
    "    def train_GD(self):\n",
    "        gan = self.gan\n",
    "        n_batch = self.n_batch\n",
    "        data = self.data\n",
    "        Z = data.in_sample(n_batch)\n",
    "\n",
    "        gan.D.trainable = False\n",
    "        print('train_GD')\n",
    "        gan.GD_train_on_batch(Z)\n",
    "\n",
    "    def train_each(self, epoch):\n",
    "        print('train_each - 0:', epoch)\n",
    "        for it in range(self.n_iter_D):\n",
    "            print('train_each - 1:', epoch)\n",
    "            self.train_D()\n",
    "        for it in range(self.n_iter_G):\n",
    "            print('train_each - 2:', epoch)\n",
    "            self.train_GD()\n",
    "\n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.train_each(epoch)\n",
    "\n",
    "    def test(self, n_test):\n",
    "        gan = self.gan\n",
    "        data = self.data\n",
    "        Z = data.in_sample(n_test)\n",
    "        Gen = gan.G.predict(Z)\n",
    "        return Gen, Z\n",
    "\n",
    "    def show_hist(self, Real, Gen, Z):\n",
    "        plt.hist(Real.reshape(-1), histtype='step', label='Real')\n",
    "        plt.hist(Gen.reshape(-1), histtype='step', label='Generated')\n",
    "        plt.hist(Z.reshape(-1), histtype='step', label='Input')\n",
    "        plt.legend(loc=0)\n",
    "\n",
    "    def test_and_show(self, n_test):\n",
    "        data = self.data\n",
    "        Gen, Z = self.test(n_test)\n",
    "        Real = data.real_sample(n_test)\n",
    "        self.show_hist(Real, Gen, Z)\n",
    "        self.print_stat(Real, Gen)\n",
    "\n",
    "    def run_epochs(self, epochs, n_test):\n",
    "        self.train(epochs)\n",
    "        self.test_and_show(n_test)\n",
    "\n",
    "    def run(self, n_repeat=200, n_show=200, n_test=100):\n",
    "        for ii in range(n_repeat):\n",
    "            print('Stage', ii, '(Epoch: {})'.format(ii * n_show))\n",
    "            self.run_epochs(n_show, n_test)\n",
    "            plt.show()\n",
    "\n",
    "    def print_stat(self, Real, Gen):\n",
    "        def stat(d):\n",
    "            return (np.mean(d), np.std(d))\n",
    "        print('Mean and Std of Real:', stat(Real))\n",
    "        print('Mean and Std of Gen:', stat(Gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_decorate(x):\n",
    "    m = K.mean(x, axis=-1, keepdims=True)\n",
    "    d = K.square(x - m)\n",
    "    return K.concatenate([x,d], axis=-1)\n",
    "\n",
    "def add_decorate_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(input_shape) == 2\n",
    "    shape[1] *= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "lr = 2e-4\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "def model_compile(model):\n",
    "    return model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, ni_D, nh_D, nh_G):\n",
    "        self.ni_D = ni_D\n",
    "        self.nh_D = nh_D\n",
    "        self.nh_G = nh_G\n",
    "        \n",
    "        self.D = self.gen_D()\n",
    "        self.G = self.gen_G()\n",
    "        self.GD = self.make_GD()\n",
    "    \n",
    "    def gen_D(self):\n",
    "        ni_D = self.ni_D\n",
    "        nh_D = self.nh_D\n",
    "        \n",
    "        D = models.Sequential()\n",
    "        D.add(Lambda(add_decorate, output_shape=add_decorate_shape, input_shape=(ni_D,)))\n",
    "        \n",
    "        D.add(Dense(nh_D, activation='relu'))\n",
    "        D.add(Dense(nh_D, activation='relu'))\n",
    "        D.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model_compile(D)\n",
    "\n",
    "        print('D.summary()')\n",
    "        D.summary()\n",
    "        return D\n",
    "    \n",
    "    def gen_G(self):\n",
    "        ni_D = self.ni_D\n",
    "        nh_G = self.nh_G\n",
    "        \n",
    "        G = models.Sequential()\n",
    "        G.add(Reshape((ni_D, 1), input_shape=(ni_D,)))\n",
    "        G.add(Conv1D(nh_G, 1, activation='relu'))\n",
    "        G.add(Conv1D(nh_G, 1, activation='sigmoid'))\n",
    "        G.add(Conv1D(1, 1))\n",
    "        G.add(Flatten())\n",
    "        \n",
    "        model_compile(G)\n",
    "        \n",
    "        print('G.summary()')\n",
    "        G.summary()\n",
    "        return G\n",
    "    \n",
    "    def make_GD(self):\n",
    "        G, D = self.G, self.D\n",
    "        GD = models.Sequential()\n",
    "        GD.add(G)\n",
    "        GD.add(D)\n",
    "        D.trainable = False\n",
    "        model_compile(GD)\n",
    "        print('GD.summary()')\n",
    "        GD.summary()\n",
    "        D.trainable = True\n",
    "        return GD\n",
    "    \n",
    "    def D_train_on_batch(self, Real, Gen):\n",
    "        D = self.D\n",
    "        X = np.concatenate([Real, Gen], axis=0)\n",
    "        y = np.array([1]*Real.shape[0] + [0]*Gen.shape[0])\n",
    "        \n",
    "        print('X.shape',X.shape)\n",
    "        print('y.shape',y.shape)\n",
    "        print(X)        \n",
    "        print(y)\n",
    "        D.train_on_batch(X, y)\n",
    "#        D.fit(X,y)\n",
    "        \n",
    "    def GD_train_on_batch(self, Z):\n",
    "        GD = self.GD\n",
    "        y = np.array([1]*Z.shape[0])\n",
    "        print('Z.shape',Z.shape)\n",
    "        print('y.shape',y.shape)\n",
    "        print(Z)        \n",
    "        print(y)\n",
    "        \n",
    "        \n",
    "        GD.train_on_batch(Z, y)\n",
    "#        GD.fit(Z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.summary()\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,651\n",
      "Trainable params: 12,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "G.summary()\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 50)           100       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 100, 50)           2550      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 100, 1)            51        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,701\n",
      "Trainable params: 2,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "GD.summary()\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 100)               2701      \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 12651     \n",
      "=================================================================\n",
      "Total params: 15,352\n",
      "Trainable params: 2,701\n",
      "Non-trainable params: 12,651\n",
      "_________________________________________________________________\n",
      "Stage 0 (Epoch: 0)\n",
      "train_each - 0: 0\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[4.57516212 4.84392473 4.87531339 3.26876099 4.73034398 3.54039292\n",
      "  2.28082478 4.12415899 3.89799962 3.36241799 2.84724929 4.27936043\n",
      "  3.27197938 3.92100512 4.00383692 5.20332853 5.20396087 4.57067443\n",
      "  3.72446976 4.31602657 3.49248479 3.35475028 3.81097178 5.41672286\n",
      "  5.58103308 3.8137185  4.91224323 1.39495992 5.05821675 3.50720269\n",
      "  4.63003377 4.58784587 3.1319942  2.9876368  4.93867853 2.1678205\n",
      "  6.43924431 2.49445228 5.37200727 4.66822257 2.43825464 2.78609123\n",
      "  2.68915018 6.09321826 2.06113141 5.85563815 3.09952771 4.18978895\n",
      "  2.00100089 4.50158152 5.13196888 2.80653791 1.87834383 4.71450388\n",
      "  7.30445469 4.29170426 3.1129597  3.99224099 3.39424873 4.3508202\n",
      "  3.20392921 2.53655241 2.30502302 6.41658246 4.67392547 5.41284566\n",
      "  2.74577382 4.90498872 1.30803749 2.94594509 2.26377671 4.46400303\n",
      "  3.67100706 2.64247488 3.76031864 4.71156752 4.96045673 3.28879033\n",
      "  4.03830665 2.27193772 5.70405864 1.85909327 4.16849599 2.93782559\n",
      "  2.27878143 5.62610684 4.15254666 4.42597486 2.80952318 4.83161106\n",
      "  3.66268214 4.73246454 4.78243297 5.8163462  6.06011005 3.60998773\n",
      "  5.52228015 2.58395691 3.20067586 3.08843966]\n",
      " [1.28435016 1.25429416 1.23505282 1.3047421  1.2540431  1.28288388\n",
      "  1.25003684 1.28559005 1.28418219 1.26856673 1.22454536 1.24310708\n",
      "  1.24880922 1.2985549  1.23898232 1.28152752 1.3036648  1.22946239\n",
      "  1.2946676  1.2866894  1.24549007 1.29747069 1.2611469  1.31323183\n",
      "  1.23646808 1.24433768 1.27868927 1.28939986 1.25201631 1.29354453\n",
      "  1.22208095 1.28022504 1.29929948 1.23587406 1.22991908 1.22767627\n",
      "  1.28224277 1.22521377 1.23844206 1.29777646 1.22238803 1.23761618\n",
      "  1.25780714 1.26378667 1.26315641 1.28861046 1.31272709 1.28159463\n",
      "  1.28391719 1.25096035 1.24114454 1.24957359 1.26150811 1.30744076\n",
      "  1.29333735 1.25321662 1.25066912 1.27624536 1.28425694 1.22682989\n",
      "  1.25871825 1.24757826 1.27880549 1.29119718 1.28583634 1.27725887\n",
      "  1.24707651 1.30164981 1.30013597 1.23281121 1.24297929 1.23804986\n",
      "  1.22986889 1.27010703 1.24601328 1.26198077 1.26088107 1.30128658\n",
      "  1.31091917 1.29544091 1.27846217 1.30471766 1.29988515 1.25450253\n",
      "  1.2787863  1.26629102 1.29785216 1.23698258 1.30716038 1.24077046\n",
      "  1.31347144 1.27145302 1.30605936 1.25570571 1.30455375 1.2419914\n",
      "  1.31347215 1.26435566 1.23050594 1.2424742 ]]\n",
      "[1 0]\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[3.66991721 4.09790848 3.67386557 5.26316627 4.57640183 4.52739496\n",
      "  4.54027578 4.93692581 1.54590379 3.14571692 5.24472538 6.2359428\n",
      "  2.71426146 4.98534492 3.64573378 3.81957185 2.34781026 3.35802118\n",
      "  3.89781192 3.51957582 2.97253455 2.74573668 5.08417121 2.13435197\n",
      "  3.58151502 5.63180251 4.14864963 1.52643862 4.89106316 3.43829701\n",
      "  2.29254488 3.26372803 3.85458284 3.84351484 4.08641131 3.97852747\n",
      "  2.60055047 2.81514628 2.75047549 5.4693979  4.02528018 4.32932173\n",
      "  4.67089148 3.66501088 4.62887215 6.92270835 4.22282182 3.98816602\n",
      "  5.43393329 2.85556267 4.98277256 4.23115624 1.88556547 3.66710349\n",
      "  3.81584812 2.15018282 1.23837214 3.73050083 4.16469115 2.81781913\n",
      "  5.56722453 5.63109919 3.47271592 4.92769971 3.48686034 4.10234633\n",
      "  3.20522118 3.94944127 5.0448779  2.74775372 5.69794376 0.27519874\n",
      "  7.42549227 3.74371001 7.29837212 4.76838012 4.65963488 3.13602582\n",
      "  2.11834693 2.39807018 2.15447858 3.90741775 6.03854681 5.0760645\n",
      "  2.65304245 2.65090019 2.8703931  3.77079035 4.51828791 4.49159336\n",
      "  2.43900838 2.16208795 4.90835241 4.67667107 2.92064087 2.92961128\n",
      "  5.38791408 3.2628785  1.77820049 4.05974296]\n",
      " [1.28602087 1.29143119 1.25959933 1.23113012 1.26195359 1.23361492\n",
      "  1.24878621 1.24063277 1.24351907 1.30600429 1.25942647 1.30992842\n",
      "  1.24464667 1.23790932 1.25297534 1.2476207  1.28849626 1.25797772\n",
      "  1.27771354 1.22390497 1.28317142 1.25403798 1.2337656  1.24362195\n",
      "  1.27099705 1.22624421 1.26351452 1.31259859 1.22750902 1.26157701\n",
      "  1.30189455 1.24166203 1.30492926 1.29830205 1.24917686 1.29954445\n",
      "  1.3110137  1.29264009 1.22154415 1.25       1.26146019 1.26606679\n",
      "  1.2718786  1.3012507  1.24959433 1.29834354 1.30126667 1.22457671\n",
      "  1.29575884 1.24761832 1.28917968 1.22724879 1.28627253 1.28590834\n",
      "  1.31104672 1.23405659 1.26328671 1.26955807 1.2933507  1.30927396\n",
      "  1.30683732 1.31374264 1.31242645 1.30354857 1.26422763 1.24749875\n",
      "  1.24513137 1.27232254 1.30109549 1.27155268 1.30509782 1.29716301\n",
      "  1.22286499 1.24522519 1.29488182 1.22844195 1.28732109 1.30259192\n",
      "  1.2359966  1.28842831 1.28285396 1.22923648 1.24133468 1.26829803\n",
      "  1.28776789 1.22406292 1.25599754 1.24451625 1.31000686 1.30394411\n",
      "  1.30582058 1.30757558 1.29624188 1.26623833 1.30104816 1.30272686\n",
      "  1.29190791 1.22348666 1.31235015 1.28213143]]\n",
      "[1 0]\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[4.21452176 4.55738577 1.64411376 5.98800261 3.2940889  4.21437909\n",
      "  4.16768171 5.60789076 3.47897781 1.78677842 4.59312789 3.88201669\n",
      "  5.57188606 5.42101096 5.16077664 2.49754379 4.36471441 5.53168342\n",
      "  5.00962428 3.45260779 4.11159533 4.40696358 3.67884251 3.66361912\n",
      "  5.52336197 4.6965532  5.82221871 4.78045163 4.04662808 4.31885666\n",
      "  4.43907744 3.9148622  4.21393387 2.7352648  3.58880199 5.16215372\n",
      "  3.46071821 3.05935644 3.00686704 4.41720525 1.6404993  3.45766022\n",
      "  3.57113932 4.10003364 3.92425298 3.60534346 3.83042884 4.08344418\n",
      "  4.75059302 5.54487117 4.09662632 2.58859174 4.01304886 5.25267602\n",
      "  3.41699949 4.79962679 4.96370504 4.87975277 4.63360019 3.22888896\n",
      "  2.23738894 2.69753901 4.96303979 3.51419202 1.67014891 3.27435182\n",
      "  2.93156654 4.98722561 3.68618264 4.69816622 4.26278469 4.48061838\n",
      "  5.51995069 2.34775366 5.31351946 4.15221617 4.75861722 3.8745426\n",
      "  1.73371195 2.38293823 3.95097879 4.11660049 3.85415683 4.25499361\n",
      "  3.40253687 2.42340941 4.26246634 5.39847214 5.41359875 6.23612901\n",
      "  4.89416575 4.59356115 2.99321026 6.40061591 3.49100071 3.72254714\n",
      "  4.78194213 3.78456618 0.46149806 3.64046905]\n",
      " [1.23526847 1.27600992 1.28046262 1.31150246 1.22796822 1.3095839\n",
      "  1.27809596 1.24043119 1.27072322 1.28598654 1.27550089 1.27376354\n",
      "  1.31192076 1.28438568 1.26819754 1.29964256 1.23467362 1.30276346\n",
      "  1.25109363 1.24702811 1.26765311 1.28310883 1.29367065 1.24722683\n",
      "  1.2751255  1.26273799 1.24787259 1.29563904 1.25160968 1.23567903\n",
      "  1.31212974 1.28805935 1.3072778  1.27431047 1.26054227 1.27911115\n",
      "  1.2889899  1.27737796 1.29574347 1.28992653 1.24750459 1.28347576\n",
      "  1.23335779 1.27805734 1.24515116 1.30584943 1.24775493 1.26112819\n",
      "  1.23343289 1.27511656 1.26880705 1.28694344 1.27178478 1.30818391\n",
      "  1.29628897 1.29033816 1.27550876 1.2902658  1.25647438 1.28518212\n",
      "  1.2294817  1.30026042 1.26871479 1.23141956 1.22859013 1.31385422\n",
      "  1.27847409 1.23089516 1.24671447 1.2450403  1.25479007 1.23866594\n",
      "  1.31233799 1.30452478 1.24247694 1.24824989 1.226542   1.25066936\n",
      "  1.2277801  1.25473285 1.29231834 1.29579318 1.2462374  1.26435757\n",
      "  1.28254449 1.29528046 1.27387345 1.28410983 1.23228037 1.25418913\n",
      "  1.27860236 1.25876677 1.24999273 1.30621767 1.28064227 1.28607297\n",
      "  1.28419614 1.27786851 1.28691185 1.25848794]]\n",
      "[1 0]\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[4.1663046  4.83514713 5.87766082 3.72079708 2.34567487 5.6487131\n",
      "  6.20215631 6.00996073 8.02276527 4.6446647  1.4190935  4.84620314\n",
      "  4.01634956 3.4074559  4.17198822 4.35931191 3.81562301 3.70503592\n",
      "  3.15125525 3.32235443 6.15598148 4.63979005 5.47812187 5.7717983\n",
      "  2.03123619 4.57176724 3.67761617 4.32475129 5.77611412 3.86811544\n",
      "  4.89004599 3.51494681 2.7949748  2.27439327 3.2822161  2.22671309\n",
      "  3.74045882 5.16363228 3.92732212 3.77281666 2.94238241 4.15929615\n",
      "  5.3949629  2.84432428 4.12415529 4.27104085 1.47222791 2.88040232\n",
      "  2.71047389 4.15944673 4.83892906 3.78823617 2.71472806 4.61984722\n",
      "  2.64092998 3.80442333 4.41414829 4.94232344 5.36068164 4.83654673\n",
      "  4.1540403  3.88821431 3.31376636 4.63349339 4.09417492 2.28403352\n",
      "  4.47551818 5.11269532 2.86924325 3.26504479 3.7008363  4.71609567\n",
      "  3.93922809 5.71622414 4.3070311  4.44330943 6.04646967 3.5230851\n",
      "  3.86028271 2.68426226 4.04178228 4.66324682 5.43042059 4.38455514\n",
      "  2.66160445 4.44725602 3.1339107  3.84869869 4.93998831 4.68508993\n",
      "  3.28774109 4.24682332 4.10426323 3.9754616  3.40067359 5.68493131\n",
      "  2.52088682 4.05932354 4.40619534 5.87260149]\n",
      " [1.22491038 1.26171505 1.28699565 1.27053547 1.31190073 1.29381168\n",
      "  1.30334544 1.2284863  1.26649332 1.23890078 1.26271784 1.30070972\n",
      "  1.24191821 1.25122762 1.27553523 1.22766817 1.28186226 1.23806429\n",
      "  1.31346929 1.22821808 1.27145731 1.28091061 1.23749816 1.29361176\n",
      "  1.28990698 1.24405217 1.30142248 1.24442923 1.28919005 1.28274596\n",
      "  1.27521598 1.29546082 1.2971046  1.29910052 1.28482664 1.23100615\n",
      "  1.22464705 1.2392931  1.24212289 1.24422002 1.28761935 1.26130915\n",
      "  1.230129   1.29525721 1.25371134 1.30206025 1.22814834 1.23731303\n",
      "  1.22516406 1.2349577  1.24110079 1.24290693 1.27537441 1.31023121\n",
      "  1.26420176 1.30893397 1.23144066 1.27279508 1.26714098 1.30861175\n",
      "  1.27964604 1.28303826 1.22144043 1.25192821 1.26594734 1.2465328\n",
      "  1.24774027 1.24112666 1.3125006  1.25999177 1.30072641 1.2237159\n",
      "  1.27704775 1.29101574 1.23416448 1.23924649 1.25272071 1.2359761\n",
      "  1.28865635 1.2852149  1.22868299 1.26574063 1.24377751 1.27713621\n",
      "  1.26436007 1.25462592 1.26972878 1.22424209 1.25623155 1.29072428\n",
      "  1.24874282 1.25124753 1.25772369 1.27702653 1.31178701 1.24204838\n",
      "  1.24472582 1.29383922 1.25762165 1.25515306]]\n",
      "[1 0]\n",
      "train_each - 1: 0\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[4.99551777 3.0670793  4.11759041 2.65758142 4.4295617  4.28089952\n",
      "  5.01450451 2.46448852 1.29143557 2.1112741  3.25218349 6.13425867\n",
      "  2.64037927 4.10085966 2.58425088 4.14833561 3.03135899 4.77221648\n",
      "  3.89666732 4.2108952  4.5203726  3.56580286 4.14240312 4.0795174\n",
      "  1.81423483 3.65393357 4.18902011 2.78199864 3.83886244 3.58203882\n",
      "  2.86280055 5.3354392  4.56028425 6.03482783 4.23438851 4.41648136\n",
      "  4.26324426 3.33489158 2.56538422 5.12029699 4.49416014 3.30975707\n",
      "  4.2843144  4.44736874 2.68985642 3.38243688 3.11032574 6.39464066\n",
      "  5.12382606 5.14271955 5.1809016  3.33623357 0.65725613 4.80580285\n",
      "  2.48993875 4.03323256 3.32862252 5.61043065 4.41214572 1.66489718\n",
      "  2.75769567 5.35186541 3.49625014 5.25306343 3.75597317 4.00871818\n",
      "  2.58532847 1.92305465 2.97645712 4.05493203 5.47525548 4.02828412\n",
      "  5.01621162 3.42859492 5.40539461 3.42772672 2.95028448 2.84299134\n",
      "  2.11133169 5.20223515 3.9325411  3.48000046 5.3287504  8.66281738\n",
      "  2.78357928 2.5941295  3.93244385 3.9036572  2.51056065 3.9591943\n",
      "  4.03984345 5.91864625 4.49938273 3.27430197 4.76645589 3.79881972\n",
      "  4.93849824 4.97322307 2.90774244 2.13409683]\n",
      " [1.30314398 1.29593372 1.22960258 1.26361775 1.31213558 1.26879108\n",
      "  1.24815428 1.28940427 1.25423288 1.23349571 1.25162804 1.22176516\n",
      "  1.26510537 1.24962342 1.24174297 1.25152957 1.23941112 1.25090969\n",
      "  1.24036217 1.30913556 1.26945424 1.29205704 1.24447405 1.26290131\n",
      "  1.25151479 1.28926635 1.25386178 1.26545691 1.24283874 1.2248733\n",
      "  1.3044951  1.27268302 1.29130304 1.2290256  1.2455771  1.30465913\n",
      "  1.24048364 1.26798296 1.24620771 1.23366344 1.24929047 1.30955267\n",
      "  1.24590456 1.23112404 1.24092448 1.26527679 1.24518859 1.27498126\n",
      "  1.22745824 1.31253231 1.23050606 1.24925745 1.29910684 1.25967443\n",
      "  1.24752784 1.26463819 1.28360415 1.29047036 1.3028928  1.23191822\n",
      "  1.24593997 1.2626915  1.22918308 1.227368   1.25778472 1.2634387\n",
      "  1.25567698 1.28321743 1.24555361 1.25155032 1.27057719 1.31084538\n",
      "  1.26100278 1.25055456 1.25703108 1.27456319 1.26196718 1.30447865\n",
      "  1.2502569  1.28454006 1.24959171 1.22726738 1.26263165 1.22295296\n",
      "  1.26884568 1.25511396 1.26367998 1.27948201 1.2740252  1.28128362\n",
      "  1.2840451  1.27180719 1.22544003 1.25090396 1.26509106 1.28751886\n",
      "  1.29709733 1.23012662 1.28550839 1.29733098]]\n",
      "[1 0]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.1997945  0.25345248 0.61834463 0.77485712 0.26653399 0.28513835\n",
      "  0.46885006 0.01722667 0.19018962 0.00949535 0.02138405 0.15156291\n",
      "  0.12866896 0.78884576 0.58572817 0.69116741 0.64304762 0.67771288\n",
      "  0.14928521 0.90107769 0.25499571 0.99977289 0.63631515 0.66238709\n",
      "  0.30057935 0.16291036 0.94328845 0.83582655 0.59696162 0.72421636\n",
      "  0.31617898 0.76018679 0.34710336 0.25162874 0.39818449 0.03694269\n",
      "  0.58162723 0.19796465 0.99401639 0.25411819 0.93358526 0.38162323\n",
      "  0.40576034 0.78507671 0.18435378 0.88680862 0.3562108  0.22997453\n",
      "  0.08494127 0.64724193 0.21759535 0.45097417 0.45902988 0.67211282\n",
      "  0.2096456  0.12677081 0.09970387 0.20694699 0.90773802 0.12970539\n",
      "  0.34095304 0.14225501 0.14695675 0.99735632 0.79263334 0.18859396\n",
      "  0.95770858 0.23496455 0.59464835 0.94009843 0.13263908 0.84687955\n",
      "  0.39130777 0.5924828  0.58539754 0.51172813 0.14896762 0.22549308\n",
      "  0.3982487  0.2919727  0.1444367  0.64134409 0.29993526 0.38570522\n",
      "  0.35042289 0.37636548 0.36005338 0.96983807 0.06750446 0.57262113\n",
      "  0.563029   0.04600932 0.52856337 0.21271793 0.04670995 0.76240648\n",
      "  0.57101559 0.10579649 0.29827077 0.77817613]]\n",
      "[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.84540367 0.71366526 0.33155166 0.37892358 0.22437006 0.07219229\n",
      "  0.87472713 0.6129173  0.49349284 0.52844913 0.3953494  0.83546552\n",
      "  0.30266538 0.60284618 0.47707026 0.40281595 0.50900517 0.37360901\n",
      "  0.35058047 0.71956792 0.86592892 0.84136784 0.83009329 0.40209246\n",
      "  0.77105792 0.48256708 0.41634328 0.59070511 0.65839667 0.60742601\n",
      "  0.82144199 0.27446773 0.22689626 0.38571832 0.68270594 0.23425215\n",
      "  0.19054224 0.62086707 0.59519217 0.22845091 0.05332775 0.43629336\n",
      "  0.11442456 0.44093392 0.4359302  0.37429397 0.91580522 0.19933727\n",
      "  0.98317596 0.3662762  0.34002033 0.11969299 0.03422602 0.01870207\n",
      "  0.45893676 0.98473399 0.17139648 0.98276418 0.58811313 0.19181672\n",
      "  0.74530189 0.67002949 0.44895809 0.20220503 0.08223713 0.11361095\n",
      "  0.08875356 0.72856668 0.51816839 0.34406681 0.88306935 0.43272951\n",
      "  0.81865885 0.59751901 0.46873649 0.08563153 0.79303521 0.20920047\n",
      "  0.09038447 0.82572269 0.43156005 0.49136459 0.18229639 0.83369696\n",
      "  0.30061835 0.7366747  0.15080077 0.4166991  0.07171459 0.99026725\n",
      "  0.7923299  0.2960938  0.99728493 0.10530822 0.03710844 0.18067044\n",
      "  0.32417274 0.96341748 0.63848685 0.75775219]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.03639573 0.29762339 0.49447978 0.28969122 0.86469109 0.80444697\n",
      "  0.03634861 0.20425331 0.88418379 0.36813978 0.93557211 0.69123648\n",
      "  0.12783952 0.67215237 0.73044696 0.55531533 0.4535177  0.23638499\n",
      "  0.141304   0.64968421 0.8272849  0.06765264 0.6448397  0.46837231\n",
      "  0.14792179 0.70635558 0.85673075 0.52690356 0.69439567 0.75375461\n",
      "  0.09059277 0.2038582  0.79955867 0.96194886 0.43080706 0.59715669\n",
      "  0.88929686 0.28197296 0.76572972 0.09257178 0.89275573 0.74157201\n",
      "  0.0850116  0.12566008 0.62542052 0.51225254 0.70193549 0.29258348\n",
      "  0.01880609 0.26254686 0.68304623 0.7759321  0.89824203 0.82622543\n",
      "  0.91199451 0.42967947 0.79436545 0.01026347 0.85744109 0.25210498\n",
      "  0.5957168  0.39803513 0.43711574 0.73589937 0.09240666 0.05801261\n",
      "  0.80240578 0.12173544 0.13067492 0.58124781 0.4393413  0.68698607\n",
      "  0.15882164 0.64311748 0.93579864 0.76097654 0.9863529  0.03197376\n",
      "  0.46429182 0.70661388 0.97793206 0.37588229 0.51592216 0.24990875\n",
      "  0.45785583 0.32082517 0.10944078 0.92033628 0.71921084 0.61701443\n",
      "  0.29123495 0.55782811 0.02133946 0.79243918 0.51049554 0.71780666\n",
      "  0.21298512 0.55467312 0.92635781 0.01282932]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[7.98403301e-01 8.88970265e-01 1.33277975e-01 6.52570640e-01\n",
      "  3.78846226e-01 3.29959553e-01 3.85440973e-01 9.48114102e-01\n",
      "  9.18969312e-01 5.37702314e-01 7.05250138e-01 5.24404310e-01\n",
      "  6.57968704e-01 3.20668628e-01 4.06284468e-01 6.60962119e-01\n",
      "  9.19219147e-01 6.09964726e-01 2.83816406e-01 5.83588803e-01\n",
      "  5.24537021e-01 3.34180792e-01 4.44386109e-01 9.66753266e-01\n",
      "  1.80414124e-01 1.48544282e-01 8.29995086e-01 2.15938375e-01\n",
      "  6.87286552e-01 6.75842143e-01 5.59114155e-01 5.53137211e-01\n",
      "  7.53080061e-01 7.73528147e-01 7.43191439e-01 6.06927512e-01\n",
      "  7.69246815e-01 7.07386841e-01 7.84434816e-01 9.02256495e-01\n",
      "  9.68795786e-01 9.59533259e-01 7.62749214e-01 7.75769277e-02\n",
      "  9.73677095e-01 1.44013689e-01 4.76909705e-01 5.78574317e-01\n",
      "  9.59691010e-01 9.02535407e-02 8.77545813e-01 5.76712370e-01\n",
      "  7.57261120e-01 3.87008156e-01 9.14315949e-01 1.16909921e-01\n",
      "  4.71893041e-01 9.94117450e-02 4.17731047e-01 7.99993427e-01\n",
      "  1.80941935e-01 1.85217351e-01 9.71875438e-01 4.60825981e-01\n",
      "  8.50482328e-01 4.56834498e-02 3.16413323e-02 9.43998458e-03\n",
      "  5.20836474e-01 7.21064057e-01 3.91400709e-01 8.46545450e-02\n",
      "  4.99968825e-01 1.81313955e-01 9.41501319e-01 4.49793919e-01\n",
      "  3.03296471e-01 3.51074903e-01 3.50307011e-01 3.36818627e-01\n",
      "  9.88834574e-01 9.87364844e-01 1.25907332e-01 3.91775379e-01\n",
      "  4.44321970e-01 7.67169724e-01 9.07016765e-01 9.62032646e-01\n",
      "  9.29480439e-01 5.19132843e-01 3.29484032e-01 1.03825504e-01\n",
      "  9.34340049e-01 1.58183468e-01 5.14259959e-01 3.45103587e-01\n",
      "  5.72697734e-02 9.86409088e-01 8.70013556e-01 7.31152976e-04]]\n",
      "[1]\n",
      "train_each - 2: 0\n",
      "train_GD\n",
      "Z.shape (1, 100)\n",
      "y.shape (1,)\n",
      "[[0.59546621 0.6161247  0.96154154 0.40568586 0.48555029 0.94005008\n",
      "  0.09128799 0.07018144 0.53158306 0.92173203 0.37587388 0.30463622\n",
      "  0.04840099 0.24425735 0.52413266 0.09813181 0.76339965 0.38657498\n",
      "  0.24633373 0.80555847 0.28794443 0.66555234 0.56885156 0.50404492\n",
      "  0.62809292 0.65026921 0.00914914 0.64129137 0.23670459 0.84986819\n",
      "  0.21659525 0.5015008  0.16303856 0.21579331 0.52450059 0.80022985\n",
      "  0.83566689 0.98425109 0.15631309 0.64465908 0.82402051 0.64626227\n",
      "  0.37705009 0.00429194 0.27948579 0.21625302 0.90822981 0.01359885\n",
      "  0.59825354 0.72124013 0.60358887 0.87611204 0.04066241 0.27289705\n",
      "  0.3748478  0.62196201 0.35977541 0.72019058 0.68250694 0.30020978\n",
      "  0.95978242 0.12305491 0.71256897 0.49306894 0.93053315 0.28799048\n",
      "  0.16826597 0.72211294 0.68237094 0.11798479 0.16465164 0.09490394\n",
      "  0.82541465 0.67829245 0.18128809 0.41007763 0.14530164 0.81945443\n",
      "  0.40348113 0.23717148 0.01198492 0.65707892 0.18045508 0.43546482\n",
      "  0.53313032 0.14248374 0.85080821 0.51008102 0.29614981 0.93519565\n",
      "  0.08678851 0.85829014 0.8991457  0.30539308 0.85355039 0.83948676\n",
      "  0.55005391 0.94579888 0.04030833 0.5929234 ]]\n",
      "[1]\n",
      "train_each - 0: 1\n",
      "train_each - 1: 1\n",
      "train_D\n",
      "X.shape (2, 100)\n",
      "y.shape (2,)\n",
      "[[3.01229499 2.08976295 4.15051649 6.32320992 4.76872601 2.57012236\n",
      "  4.53417237 6.19192048 3.3584993  4.21286609 3.9977717  6.00667369\n",
      "  5.91424173 3.46233368 3.63411282 4.71739725 4.57537444 3.84906016\n",
      "  5.34138579 2.56392797 2.24235469 6.02796327 3.56243086 5.27101056\n",
      "  2.87897062 4.62617849 2.70006272 4.31288616 3.7337415  2.27655028\n",
      "  3.87446826 2.42337197 2.50050591 6.09206935 5.23265108 2.77517992\n",
      "  3.41932878 5.79879074 4.04179945 6.49228775 4.97472749 5.06506005\n",
      "  2.32230167 4.37172458 4.23119474 3.632057   4.22531068 4.78914331\n",
      "  4.41972103 4.83075621 5.18408219 6.75826553 5.22580237 4.7652783\n",
      "  3.73299352 3.94840507 2.27101676 3.87385706 3.96556802 2.75017386\n",
      "  5.47693612 3.34124171 0.79683314 3.52124261 4.63028111 3.52088667\n",
      "  4.06084859 5.54429552 3.0856044  2.00928814 3.45307177 2.31414438\n",
      "  5.63982063 5.35914574 4.13699537 2.68340839 3.9080271  2.14070369\n",
      "  5.20881255 4.07006603 5.02163808 4.61256482 3.25851729 4.34680776\n",
      "  3.39609661 3.75374274 5.70804204 5.93204577 3.47278322 5.36410773\n",
      "  4.54321493 4.18445512 6.09975615 4.02211641 3.28299826 4.5050676\n",
      "  2.0542404  2.28681046 3.18699694 4.52447237]\n",
      " [1.27552521 1.26703644 1.30952656 1.31603086 1.27280223 1.26306701\n",
      "  1.31096375 1.25927746 1.29148698 1.28526318 1.31105375 1.27231455\n",
      "  1.29704988 1.29743445 1.29273009 1.2851578  1.2947216  1.3135699\n",
      "  1.27872348 1.31238592 1.26257181 1.28324437 1.33132875 1.29658604\n",
      "  1.26448333 1.26941288 1.30530369 1.29951715 1.2538501  1.33476138\n",
      "  1.27045977 1.30142045 1.24649751 1.25224841 1.26096892 1.33430779\n",
      "  1.32688951 1.24655509 1.29206967 1.27057767 1.26582897 1.25597262\n",
      "  1.31973827 1.28590703 1.32503593 1.26010036 1.27193284 1.32641864\n",
      "  1.30894566 1.24949384 1.29205906 1.32979238 1.32468677 1.33273661\n",
      "  1.26862216 1.25910306 1.29485929 1.26371276 1.26031244 1.33003747\n",
      "  1.28201723 1.24542642 1.29389715 1.32134902 1.31771743 1.31753957\n",
      "  1.24761188 1.33037007 1.31251037 1.28986347 1.3100251  1.26965714\n",
      "  1.25040078 1.30183399 1.31615233 1.28127623 1.301054   1.26516426\n",
      "  1.30349326 1.3305496  1.24664176 1.24682367 1.24725068 1.29894733\n",
      "  1.28421295 1.31862211 1.24604142 1.29695618 1.29186189 1.2604934\n",
      "  1.25335026 1.32428551 1.26329279 1.28505361 1.33012068 1.28157115\n",
      "  1.28480375 1.27036166 1.31341445 1.27633691]]\n",
      "[1 0]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": " Error while reading resource variable _AnonymousVar34 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar34/N10tensorflow3VarE does not exist.\n\t [[node mul_28/ReadVariableOp (defined at /home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_1426]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e69b69f01a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#keras.backend.get_session().run(tf.global_variables_initializer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mni_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_show\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ea357f3903ab>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_repeat, n_show, n_test)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(Epoch: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_show\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ea357f3903ab>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, epochs, n_test)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_and_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ea357f3903ab>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ea357f3903ab>\u001b[0m in \u001b[0;36mtrain_each\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_each - 1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_each - 2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ea357f3903ab>\u001b[0m in \u001b[0;36mtrain_D\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_train_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7eba22c560a4>\u001b[0m in \u001b[0;36mD_train_on_batch\u001b[0;34m(self, Real, Gen)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;31m#        D.fit(X,y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/udemy/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable _AnonymousVar34 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar34/N10tensorflow3VarE does not exist.\n\t [[node mul_28/ReadVariableOp (defined at /home/inswave/anaconda3/envs/udemy/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_1426]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.python.keras.backend as K\n",
    "#sess = K.get_session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "machine = Machine(n_batch=1, ni_D=100)\n",
    "machine.run(n_repeat=200, n_show=200, n_test=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
