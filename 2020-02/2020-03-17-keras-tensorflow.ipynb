{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 2.0에서는 오류가 발생\n",
    "# conda activate keras205 \n",
    "# nohup jupyter notebook --ip 192.168.1.120 & \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN():\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        self.X_ph = tf.placeholder(tf.float32, shape=(None, Nin))\n",
    "        self.L_ph = tf.placeholder(tf.float32, shape=(None, Nout))\n",
    "        \n",
    "        H = Dense(Nh_l[0], activation='relu')(self.X_ph)\n",
    "        H = Dropout(0.5)(H)\n",
    "        H = Dense(Nh_l[1], activation='relu')(H)\n",
    "        H = Dropout(0.25)(H)\n",
    "        self.Y_tf = Dense(Nout, activation='softmax')(H)\n",
    "        self.Loss_tf = tf.reduce_mean(categorical_crossentropy(self.L_ph, self.Y_tf))\n",
    "        self.Train_tf = tf.train.AdamOptimizer().minimize(self.Loss_tf)\n",
    "        self.Acc_tf = categorical_accuracy(self.L_ph, self.Y_tf)\n",
    "        self.Init_tf = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "    \n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "    \n",
    "    L, W, H = X_train.shape\n",
    "    print('X_train.shape', X_train.shape)\n",
    "    X_train = X_train.reshape(-1, W * H)\n",
    "    print('X_train.shape', X_train.shape)\n",
    "    X_test = X_test.reshape(-1, W * H)\n",
    "    \n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, data, sess, epochs, batch_size=100):\n",
    "    (X_train, Y_train), (X_test, Y_test) = data\n",
    "    sess.run(model.Init_tf)\n",
    "    with sess.as_default():\n",
    "        N_tr = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            for b in range(N_tr // batch_size):\n",
    "                X_tr_b = X_train[batch_size * (b-1):batch_size * b]\n",
    "                Y_tr_b = Y_train[batch_size * (b-1):batch_size * b]\n",
    "                \n",
    "                model.Train_tf.run(feed_dict={model.X_ph: X_tr_b, model.L_ph: Y_tr_b, K.learning_phase(): 1})\n",
    "                \n",
    "            loss = sess.run(model.Loss_tf, feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            acc = model.Acc_tf.eval(feed_dict={model.X_ph: X_test, model.L_ph: Y_test, K.learning_phase(): 0})\n",
    "            print(\"Epoch {0}: loss = {1:.3f}, acc = {2:.3f}\".format(epoch, loss, np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Nin = 784\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "    data = Data_func()\n",
    "    model = DNN(Nin, Nh_l, Nout)\n",
    "    run(model, data, sess, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (60000, 28, 28)\n",
      "X_train.shape (60000, 784)\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2880: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2747: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2751: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/inswave/anaconda3/envs/keras205/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 0: loss = 0.223, acc = 0.932\n",
      "Epoch 1: loss = 0.168, acc = 0.949\n",
      "Epoch 2: loss = 0.146, acc = 0.956\n",
      "Epoch 3: loss = 0.135, acc = 0.960\n",
      "Epoch 4: loss = 0.120, acc = 0.964\n",
      "Epoch 5: loss = 0.116, acc = 0.967\n",
      "Epoch 6: loss = 0.113, acc = 0.968\n",
      "Epoch 7: loss = 0.107, acc = 0.969\n",
      "Epoch 8: loss = 0.104, acc = 0.968\n",
      "Epoch 9: loss = 0.103, acc = 0.970\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
